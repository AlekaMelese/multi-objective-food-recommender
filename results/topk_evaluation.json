{
  "evaluation_type": "Top-K Recommendation Quality",
  "k": 10,
  "rating_threshold": 4.0,
  "alpha_values": [
    0.0,
    0.25,
    0.5,
    0.75,
    1.0
  ],
  "results": [
    {
      "alpha": 0.0,
      "precision_at_k": 0.004083526682134571,
      "recall_at_k": 0.034899458623356534,
      "f1_score": 0.0073115421696785055,
      "avg_health_topk": 0.913731831708594,
      "k": 10,
      "num_users_evaluated": 2155
    },
    {
      "alpha": 0.25,
      "precision_at_k": 0.00394431554524362,
      "recall_at_k": 0.03408739365815932,
      "f1_score": 0.007070491414605492,
      "avg_health_topk": 0.9057781223907169,
      "k": 10,
      "num_users_evaluated": 2155
    },
    {
      "alpha": 0.5,
      "precision_at_k": 0.004501160092807425,
      "recall_at_k": 0.03791569992266048,
      "f1_score": 0.008047018818484238,
      "avg_health_topk": 0.8809595194030068,
      "k": 10,
      "num_users_evaluated": 2155
    },
    {
      "alpha": 0.75,
      "precision_at_k": 0.0055220417633410675,
      "recall_at_k": 0.04630703789636505,
      "f1_score": 0.009867410298591252,
      "avg_health_topk": 0.8530123299745912,
      "k": 10,
      "num_users_evaluated": 2155
    },
    {
      "alpha": 1.0,
      "precision_at_k": 0.005568445475638051,
      "recall_at_k": 0.048453209590100535,
      "f1_score": 0.009988922234752295,
      "avg_health_topk": 0.6005112282276713,
      "k": 10,
      "num_users_evaluated": 2155
    }
  ]
}