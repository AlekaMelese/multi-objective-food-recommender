
@inproceedings{aghajanyan_intrinsic_2021,
	address = {Online},
	title = {Intrinsic {Dimensionality} {Explains} the {Effectiveness} of {Language} {Model} {Fine}-{Tuning}},
	url = {https://aclanthology.org/2021.acl-long.568/},
	doi = {10.18653/v1/2021.acl-long.568},
	abstract = {Although pretrained language models can be fine-tuned to produce state-of-the-art results for a very wide range of language understanding tasks, the dynamics of this process are not well understood, especially in the low data regime. Why can we use relatively vanilla gradient descent algorithms (e.g., without strong regularization) to tune a model with hundreds of millions of parameters on datasets with only hundreds or thousands of labeled examples? In this paper, we argue that analyzing fine-tuning through the lens of intrinsic dimension provides us with empirical and theoretical intuitions to explain this remarkable phenomenon. We empirically show that common pre-trained models have a very low intrinsic dimension; in other words, there exists a low dimension reparameterization that is as effective for fine-tuning as the full parameter space. For example, by optimizing only 200 trainable parameters randomly projected back into the full space, we can tune a RoBERTa model to achieve 90\% of the full parameter performance levels on MRPC. Furthermore, we empirically show that pre-training implicitly minimizes intrinsic dimension and, perhaps surprisingly, larger models tend to have lower intrinsic dimension after a fixed number of pre-training updates, at least in part explaining their extreme effectiveness. Lastly, we connect intrinsic dimensionality with low dimensional task representations and compression based generalization bounds to provide intrinsic-dimension-based generalization bounds that are independent of the full parameter count.},
	urldate = {2025-12-24},
	booktitle = {Proceedings of the 59th {Annual} {Meeting} of the {Association} for {Computational} {Linguistics} and the 11th {International} {Joint} {Conference} on {Natural} {Language} {Processing} ({Volume} 1: {Long} {Papers})},
	publisher = {Association for Computational Linguistics},
	author = {Aghajanyan, Armen and Gupta, Sonal and Zettlemoyer, Luke},
	editor = {Zong, Chengqing and Xia, Fei and Li, Wenjie and Navigli, Roberto},
	month = aug,
	year = {2021},
	pages = {7319--7328},
}

@misc{houlsby_parameter-efficient_2019,
	title = {Parameter-{Efficient} {Transfer} {Learning} for {NLP}},
	url = {http://arxiv.org/abs/1902.00751},
	doi = {10.48550/arXiv.1902.00751},
	abstract = {Fine-tuning large pre-trained models is an effective transfer mechanism in NLP. However, in the presence of many downstream tasks, fine-tuning is parameter inefficient: an entire new model is required for every task. As an alternative, we propose transfer with adapter modules. Adapter modules yield a compact and extensible model; they add only a few trainable parameters per task, and new tasks can be added without revisiting previous ones. The parameters of the original network remain fixed, yielding a high degree of parameter sharing. To demonstrate adapter's effectiveness, we transfer the recently proposed BERT Transformer model to 26 diverse text classification tasks, including the GLUE benchmark. Adapters attain near state-of-the-art performance, whilst adding only a few parameters per task. On GLUE, we attain within 0.4\% of the performance of full fine-tuning, adding only 3.6\% parameters per task. By contrast, fine-tuning trains 100\% of the parameters per task.},
	urldate = {2025-12-24},
	publisher = {arXiv},
	author = {Houlsby, Neil and Giurgiu, Andrei and Jastrzebski, Stanislaw and Morrone, Bruna and Laroussilhe, Quentin de and Gesmundo, Andrea and Attariyan, Mona and Gelly, Sylvain},
	month = jun,
	year = {2019},
	note = {arXiv:1902.00751 [cs]},
	keywords = {Computer Science - Computation and Language, Computer Science - Machine Learning, Statistics - Machine Learning},
}

@misc{hu_lora_2021,
	title = {{LoRA}: {Low}-{Rank} {Adaptation} of {Large} {Language} {Models}},
	shorttitle = {{LoRA}},
	url = {http://arxiv.org/abs/2106.09685},
	doi = {10.48550/arXiv.2106.09685},
	abstract = {An important paradigm of natural language processing consists of large-scale pre-training on general domain data and adaptation to particular tasks or domains. As we pre-train larger models, full fine-tuning, which retrains all model parameters, becomes less feasible. Using GPT-3 175B as an example -- deploying independent instances of fine-tuned models, each with 175B parameters, is prohibitively expensive. We propose Low-Rank Adaptation, or LoRA, which freezes the pre-trained model weights and injects trainable rank decomposition matrices into each layer of the Transformer architecture, greatly reducing the number of trainable parameters for downstream tasks. Compared to GPT-3 175B fine-tuned with Adam, LoRA can reduce the number of trainable parameters by 10,000 times and the GPU memory requirement by 3 times. LoRA performs on-par or better than fine-tuning in model quality on RoBERTa, DeBERTa, GPT-2, and GPT-3, despite having fewer trainable parameters, a higher training throughput, and, unlike adapters, no additional inference latency. We also provide an empirical investigation into rank-deficiency in language model adaptation, which sheds light on the efficacy of LoRA. We release a package that facilitates the integration of LoRA with PyTorch models and provide our implementations and model checkpoints for RoBERTa, DeBERTa, and GPT-2 at https://github.com/microsoft/LoRA.},
	urldate = {2025-12-24},
	publisher = {arXiv},
	author = {Hu, Edward J. and Shen, Yelong and Wallis, Phillip and Allen-Zhu, Zeyuan and Li, Yuanzhi and Wang, Shean and Wang, Lu and Chen, Weizhu},
	month = oct,
	year = {2021},
	note = {arXiv:2106.09685 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computation and Language, Computer Science - Machine Learning},
}

@misc{yang_low-rank_2025,
	title = {Low-{Rank} {Adaptation} for {Foundation} {Models}: {A} {Comprehensive} {Review}},
	shorttitle = {Low-{Rank} {Adaptation} for {Foundation} {Models}},
	url = {http://arxiv.org/abs/2501.00365},
	doi = {10.48550/arXiv.2501.00365},
	abstract = {The rapid advancement of foundation modelslarge-scale neural networks trained on diverse, extensive datasetshas revolutionized artificial intelligence, enabling unprecedented advancements across domains such as natural language processing, computer vision, and scientific discovery. However, the substantial parameter count of these models, often reaching billions or trillions, poses significant challenges in adapting them to specific downstream tasks. Low-Rank Adaptation (LoRA) has emerged as a highly promising approach for mitigating these challenges, offering a parameter-efficient mechanism to fine-tune foundation models with minimal computational overhead. This survey provides the first comprehensive review of LoRA techniques beyond large Language Models to general foundation models, including recent techniques foundations, emerging frontiers and applications of low-rank adaptation across multiple domains. Finally, this survey discusses key challenges and future research directions in theoretical understanding, scalability, and robustness. This survey serves as a valuable resource for researchers and practitioners working with efficient foundation model adaptation.},
	urldate = {2025-12-24},
	publisher = {arXiv},
	author = {Yang, Menglin and Chen, Jialin and Tao, Jinkai and Zhang, Yifei and Liu, Jiahong and Zhang, Jiasheng and Ma, Qiyao and Verma, Harshit and Zhang, Regina and Zhou, Min and King, Irwin and Ying, Rex},
	month = nov,
	year = {2025},
	note = {arXiv:2501.00365 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Machine Learning},
}

@misc{yang_low-rank_2025-1,
	title = {Low-{Rank} {Adaptation} for {Foundation} {Models}: {A} {Comprehensive} {Review}},
	shorttitle = {Low-{Rank} {Adaptation} for {Foundation} {Models}},
	url = {http://arxiv.org/abs/2501.00365},
	doi = {10.48550/arXiv.2501.00365},
	abstract = {The rapid advancement of foundation modelslarge-scale neural networks trained on diverse, extensive datasetshas revolutionized artificial intelligence, enabling unprecedented advancements across domains such as natural language processing, computer vision, and scientific discovery. However, the substantial parameter count of these models, often reaching billions or trillions, poses significant challenges in adapting them to specific downstream tasks. Low-Rank Adaptation (LoRA) has emerged as a highly promising approach for mitigating these challenges, offering a parameter-efficient mechanism to fine-tune foundation models with minimal computational overhead. This survey provides the first comprehensive review of LoRA techniques beyond large Language Models to general foundation models, including recent techniques foundations, emerging frontiers and applications of low-rank adaptation across multiple domains. Finally, this survey discusses key challenges and future research directions in theoretical understanding, scalability, and robustness. This survey serves as a valuable resource for researchers and practitioners working with efficient foundation model adaptation.},
	urldate = {2025-12-24},
	publisher = {arXiv},
	author = {Yang, Menglin and Chen, Jialin and Tao, Jinkai and Zhang, Yifei and Liu, Jiahong and Zhang, Jiasheng and Ma, Qiyao and Verma, Harshit and Zhang, Regina and Zhou, Min and King, Irwin and Ying, Rex},
	month = nov,
	year = {2025},
	note = {arXiv:2501.00365 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Machine Learning},
}

@article{tang_evaluating_2023,
	title = {Evaluating large language models on medical evidence summarization},
	volume = {6},
	copyright = {2023 The Author(s)},
	issn = {2398-6352},
	url = {https://www.nature.com/articles/s41746-023-00896-7},
	doi = {10.1038/s41746-023-00896-7},
	abstract = {Recent advances in large language models (LLMs) have demonstrated remarkable successes in zero- and few-shot performance on various downstream tasks, paving the way for applications in high-stakes domains. In this study, we systematically examine the capabilities and limitations of LLMs, specifically GPT-3.5 and ChatGPT, in performing zero-shot medical evidence summarization across six clinical domains. We conduct both automatic and human evaluations, covering several dimensions of summary quality. Our study demonstrates that automatic metrics often do not strongly correlate with the quality of summaries. Furthermore, informed by our human evaluations, we define a terminology of error types for medical evidence summarization. Our findings reveal that LLMs could be susceptible to generating factually inconsistent summaries and making overly convincing or uncertain statements, leading to potential harm due to misinformation. Moreover, we find that models struggle to identify the salient information and are more error-prone when summarizing over longer textual contexts.},
	language = {en},
	number = {1},
	urldate = {2025-12-23},
	journal = {npj Digital Medicine},
	author = {Tang, Liyan and Sun, Zhaoyi and Idnay, Betina and Nestor, Jordan G. and Soroush, Ali and Elias, Pierre A. and Xu, Ziyang and Ding, Ying and Durrett, Greg and Rousseau, Justin F. and Weng, Chunhua and Peng, Yifan},
	month = aug,
	year = {2023},
	note = {Publisher: Nature Publishing Group},
	keywords = {Literature mining, Medical ethics, Translational research},
	pages = {158},
}

@misc{noauthor_clinical_nodate,
	title = {Clinical {Text} {Summarization}: {Adapting} {Large} {Language} {Models} {Can} {Outperform} {Human} {Experts} - {PMC}},
	url = {https://pmc.ncbi.nlm.nih.gov/articles/PMC10635391/},
	urldate = {2025-12-23},
}

@inproceedings{aghajanyan_intrinsic_2021-1,
	address = {Online},
	title = {Intrinsic {Dimensionality} {Explains} the {Effectiveness} of {Language} {Model} {Fine}-{Tuning}},
	url = {https://aclanthology.org/2021.acl-long.568},
	doi = {10.18653/v1/2021.acl-long.568},
	language = {en},
	urldate = {2025-12-23},
	booktitle = {Proceedings of the 59th {Annual} {Meeting} of the {Association} for {Computational} {Linguistics} and the 11th {International} {Joint} {Conference} on {Natural} {Language} {Processing} ({Volume} 1: {Long} {Papers})},
	publisher = {Association for Computational Linguistics},
	author = {Aghajanyan, Armen and Gupta, Sonal and Zettlemoyer, Luke},
	year = {2021},
	pages = {7319--7328},
}

@article{dhawan_healthcare_2024,
	title = {Healthcare {Data} {Sensitivity} {Assessment} {Through} {Biomedical} {NLP}-{Driven} {Classification} and {Statistical} {Feature} {Analysis}},
	volume = {5},
	issn = {2661-8907},
	url = {https://doi.org/10.1007/s42979-024-03472-2},
	doi = {10.1007/s42979-024-03472-2},
	abstract = {This study presents an application of transfer learning for biomedical NLP to ascertain the data sensitivity of data in electronic healthcare records. This work aims to improve the performance of multiclass categorization of biological texts for sensitivity evaluation by combining two distinct feature representation techniques. A variety of potential statistical weighting strategies are investigated which include the class probability (CP), inverse document frequency (IDF), and term frequency (TF) methods. These strategies combine each member of the Word Embedding (WE) vectors to integrate the two feature representations. A domain-specific adaptation of A Lite Bidirectional Encoder Representations from Transformers (Bio ALBERT), was utilized in this investigation. ALBERT was trained using biological and medical corpora. Using BioALBERT, we developed a multiclass classification model to classify the sensitivity of the data on investigated feature vector combinations. The experimental results validate the suggested system's theoretical analysis. In this work, the MIMIC-III database is used to evaluate the effectiveness and efficiency of the proposed task. Further, MIMIC III and the PubMed dataset are employed to construct the language model. The performance of the proposed weighted feature representation approach for multiclass classification is compared with other conventional techniques. The performance of the proposed model is found to be superior to the conventional techniques.},
	language = {en},
	number = {8},
	urldate = {2025-11-15},
	journal = {SN Computer Science},
	author = {Dhawan, Manoj and Purohit, Lalit},
	month = dec,
	year = {2024},
	keywords = {ALBERT, Attention mechanisms, BioALBERT, Biomedical NLP, Electronic health records (EHR), Natural language processing, Transfer learning},
	pages = {1126},
}

@article{giancani_quality_2023,
	title = {Quality of word and concept embeddings in targetted biomedical domains},
	volume = {9},
	issn = {2405-8440},
	url = {https://www.sciencedirect.com/science/article/pii/S2405844023040252},
	doi = {10.1016/j.heliyon.2023.e16818},
	abstract = {Embeddings are fundamental resources often reused for building intelligent systems in the biomedical context. As a result, evaluating the quality of previously trained embeddings and ensuring they cover the desired information is critical for the success of applications. This paper proposes a new evaluation methodology to test the coverage of embeddings against a targetted domain of interest. It defines measures to assess the terminology, similarity, and analogy coverage, which are core aspects of the embeddings. Then, it discusses the experimentation carried out on existing biomedical embeddings in the specific context of pulmonary diseases. The proposed methodology and measures are general and may be applied to any application domain.},
	number = {6},
	urldate = {2025-11-15},
	journal = {Heliyon},
	author = {Giancani, Salvatore and Albertoni, Riccardo and Catalano, Chiara Eva},
	month = jun,
	year = {2023},
	keywords = {Chronic obstructive pulmonary disease, Coverage, Embedding, Quality, UMLS},
	pages = {e16818},
}

@article{wang_comparison_2018,
	title = {A comparison of word embeddings for the biomedical natural language processing},
	volume = {87},
	issn = {1532-0464},
	url = {https://www.sciencedirect.com/science/article/pii/S1532046418301825},
	doi = {10.1016/j.jbi.2018.09.008},
	abstract = {Background
Word embeddings have been prevalently used in biomedical Natural Language Processing (NLP) applications due to the ability of the vector representations being able to capture useful semantic properties and linguistic relationships between words. Different textual resources (e.g., Wikipedia and biomedical literature corpus) have been utilized in biomedical NLP to train word embeddings and these word embeddings have been commonly leveraged as feature input to downstream machine learning models. However, there has been little work on evaluating the word embeddings trained from different textual resources.
Methods
In this study, we empirically evaluated word embeddings trained from four different corpora, namely clinical notes, biomedical publications, Wikipedia, and news. For the former two resources, we trained word embeddings using unstructured electronic health record (EHR) data available at Mayo Clinic and articles (MedLit) from PubMed Central, respectively. For the latter two resources, we used publicly available pre-trained word embeddings, GloVe and Google News. The evaluation was done qualitatively and quantitatively. For the qualitative evaluation, we randomly selected medical terms from three categories (i.e., disorder, symptom, and drug), and manually inspected the five most similar words computed by embeddings for each term. We also analyzed the word embeddings through a 2-dimensional visualization plot of 377 medical terms. For the quantitative evaluation, we conducted both intrinsic and extrinsic evaluation. For the intrinsic evaluation, we evaluated the word embeddings’ ability to capture medical semantics by measruing the semantic similarity between medical terms using four published datasets: Pedersen’s dataset, Hliaoutakis’s dataset, MayoSRS, and UMNSRS. For the extrinsic evaluation, we applied word embeddings to multiple downstream biomedical NLP applications, including clinical information extraction (IE), biomedical information retrieval (IR), and relation extraction (RE), with data from shared tasks.
Results
The qualitative evaluation shows that the word embeddings trained from EHR and MedLit can find more similar medical terms than those trained from GloVe and Google News. The intrinsic quantitative evaluation verifies that the semantic similarity captured by the word embeddings trained from EHR is closer to human experts’ judgments on all four tested datasets. The extrinsic quantitative evaluation shows that the word embeddings trained on EHR achieved the best F1 score of 0.900 for the clinical IE task; no word embeddings improved the performance for the biomedical IR task; and the word embeddings trained on Google News had the best overall F1 score of 0.790 for the RE task.
Conclusion
Based on the evaluation results, we can draw the following conclusions. First, the word embeddings trained from EHR and MedLit can capture the semantics of medical terms better, and find semantically relevant medical terms closer to human experts’ judgments than those trained from GloVe and Google News. Second, there does not exist a consistent global ranking of word embeddings for all downstream biomedical NLP applications. However, adding word embeddings as extra features will improve results on most downstream tasks. Finally, the word embeddings trained from the biomedical domain corpora do not necessarily have better performance than those trained from the general domain corpora for any downstream biomedical NLP task.},
	urldate = {2025-11-15},
	journal = {Journal of Biomedical Informatics},
	author = {Wang, Yanshan and Liu, Sijia and Afzal, Naveed and Rastegar-Mojarad, Majid and Wang, Liwei and Shen, Feichen and Kingsbury, Paul and Liu, Hongfang},
	month = nov,
	year = {2018},
	keywords = {Information extraction, Information retrieval, Machine learning, Natural language processing, Word embeddings},
	pages = {12--20},
}

@article{ayalew_explainable_2025,
	title = {An explainable hybrid deep learning system for tuberculosis detection with {Grad}-{CAM}},
	volume = {28},
	issn = {2948-2992},
	url = {https://doi.org/10.1007/s10791-025-09791-z},
	doi = {10.1007/s10791-025-09791-z},
	abstract = {Tuberculosis (TB) is a highly contagious disease that affects millions of individuals globally. Early detection is crucial in preventing its spread and improving patient outcomes. Radiologists often utilize X-ray imaging as a diagnostic tool for tuberculosis; however, the accuracy of the results may differ depending on the radiologist’s interpretation. To increase the precision of TB identification from X-ray images, a hybrid strategy combining Convolutional Neural Network, Histogram of Oriented Gradients, and Quantum Support Vector Machine (QSVM) classifier has been developed. Quantum machine learning is a rapidly growing field at the intersection of quantum computing and machine learning. By combining the strengths of both techniques, this approach aims to capture relevant features and shape and texture information of an image. The study used state-of-the-art models such as VGG16 and AlexNet, along with a handcrafted method (HOG) and a deep learning (CNN) method to detect TB from chest X-ray images. Six distinct tests were carried out by the authors to successfully diagnose tuberculosis. All models showed promise when the data was analyzed, but the best techniques involved augmentation, image preprocessing, contrast improvement, and noise filtering. The block-matching and 3D filtering approach was used to improve image edge preservation and reduce noise. In this study, Grad-CAM (gradient-weighted class activation map) was applied to the convolutional neural network model to identify the model’s important features (explainability) for decision-making. This focus on Explainable AI (XAI) is crucial for clinical adoption, as it provides radiologists with visual evidence of the model’s reasoning, fostering trust and enabling more informed decisions. The hybrid model was found to have achieved an exceptional level of accuracy in detecting and classifying TB, with an accuracy rate of 100\% during training, 99.07\% during validation, and 98.14\% during testing. These results highlight the effectiveness of the hybrid model in accurately identifying TB and its potential to be a valuable tool in the fight against this disease.},
	language = {en},
	number = {1},
	urldate = {2025-11-14},
	journal = {Discover Computing},
	author = {Ayalew, Aleka Melese and Asnake, Nigus Wereta and Demil, Getnet and Oussalah, Mourad},
	month = nov,
	year = {2025},
	keywords = {CNN, Chest X-ray, Grad-CAM, HOG, Quantum classifier, Tuberculosis},
	pages = {262},
}

@article{bezabh_classification_2024,
	title = {Classification of cervical spine disease using convolutional neural network},
	volume = {83},
	issn = {1573-7721},
	url = {https://doi.org/10.1007/s11042-024-18970-x},
	doi = {10.1007/s11042-024-18970-x},
	abstract = {Cervical spondylosis myelopathy (CSM) is a degenerative disorder of the cervical spine’s disks and joints, leading to neurological disability. Typically, this condition causes increasing discomfort and neurologic deterioration. Cervical spine pain disease classification using deep learning can assist medical professionals in making early and more precise medical diagnosis of cervical abnormalities. The main focus of the assessment for doctors is the classification of cervical spine diseases from X-rays images, which is valuable for patients to indicate the various symptoms they are faced with. Identifying cervical spine pain injuries (CPI) is a critical aspect of the diseases segmentation and classification. Manually explaining the high-dimensional feature space makes it challenging to identify the exact category and level of severity. This paper introduces a Convolutional Neural Networks (CNN) concatenation feature extraction method to help in the diagnosis of cervical spine pain disease from X-ray images. An innovative CNN-concatenation model-based fully connected classifier and a four-class system are applied to classify X-ray image data in this research. The CNN approach is employed to automatically classify X-ray images into healthy (normal) and with cervical spine disease (abnormal). CSM is currently diagnosed mostly through clinical evaluation using imaging methods such as X-ray and computed tomography (CT). Due to its inexpensive cost and minimal radiation dose, X-ray is commonly used. The proposed approach achieved a training accuracy of 99.98\%, a validation accuracy of 98.29\%, and a testing accuracy of 97.82\% of classification from experiments. These results indicate that the image preprocessing, data augmentation, and CNN approaches provide an efficient classification method for identifying and accurately classifying cervical spine diseases.},
	language = {en},
	number = {41},
	urldate = {2025-11-14},
	journal = {Multimedia Tools and Applications},
	author = {Bezabh, Yohannes Agegnehu and Salau, Ayodeji Olalekan and Abuhayi, Biniyam Mulugeta and Ayalew, Aleka Melese},
	month = dec,
	year = {2024},
	keywords = {Cervical spine disease classification, Concatenation model, Convolutional Neural Network, Feature extraction},
	pages = {88963--88979},
}

@article{ayalew_smart_2024,
	title = {Smart {Malaria} {Classification}: {A} {Novel} {Machine} {Learning} {Algorithms} for {Early} {Malaria} {Monitoring} and {Detecting} {Using} {IoT}-{Based} {Healthcare} {Environment}},
	volume = {25},
	issn = {1557-2072},
	shorttitle = {Smart {Malaria} {Classification}},
	url = {https://doi.org/10.1007/s11220-024-00503-3},
	doi = {10.1007/s11220-024-00503-3},
	abstract = {Malaria, caused by the Plasmodium parasite and transmitted by female Anopheles mosquitoes, poses a significant risk to nearly half of the global population, with sub-Saharan Africa being the most affected. A rapid and accurate detection method is crucial due to its high mortality rate and swift transmission. This study proposes a real-time malaria monitoring and detection system using an Internet of Things (IoT) framework. The system collects real-time symptom data via wearable sensors, employs edge computing for processing, utilizes cloud infrastructure for data storage, and applies machine learning models for data analysis. The five key components of the framework are wearable sensor-based symptom data collection and uploading, edge (fog) computing, cloud infrastructure, machine learning models for data analysis, and doctors (physicians). The study compares four machine learning techniques: Support Vector Machine (SVM), Artificial Neural Network (ANN), K-Nearest Neighbor (KNN), and Naïve Bayes. SVM outperformed the other algorithms, achieving 98\% training accuracy, 96\% test accuracy, and a 95\% AUC score. Based on the findings, we anticipate that real-time symptom data would enable the proposed system can effectively and accurately diagnose malaria, classifying cases as either Parasitized or Normal.},
	language = {en},
	number = {1},
	urldate = {2025-11-14},
	journal = {Sensing and Imaging},
	author = {Ayalew, Aleka Melese and Admass, Wasyihun Sema and Abuhayi, Biniyam Mulugeta and Negashe, Girma Sisay and Bezabh, Yohannes Agegnehu},
	month = sep,
	year = {2024},
	keywords = {Early identification, Internet of Things, Machine learning, Malaria, Real-time monitoring},
	pages = {55},
}

@article{ayalew_smart_2024-1,
	title = {Smart {Malaria} {Classification}: {A} {Novel} {Machine} {Learning} {Algorithms} for {Early} {Malaria} {Monitoring} and {Detecting} {Using} {IoT}-{Based} {Healthcare} {Environment}},
	volume = {25},
	issn = {1557-2072},
	shorttitle = {Smart {Malaria} {Classification}},
	url = {https://doi.org/10.1007/s11220-024-00503-3},
	doi = {10.1007/s11220-024-00503-3},
	abstract = {Malaria, caused by the Plasmodium parasite and transmitted by female Anopheles mosquitoes, poses a significant risk to nearly half of the global population, with sub-Saharan Africa being the most affected. A rapid and accurate detection method is crucial due to its high mortality rate and swift transmission. This study proposes a real-time malaria monitoring and detection system using an Internet of Things (IoT) framework. The system collects real-time symptom data via wearable sensors, employs edge computing for processing, utilizes cloud infrastructure for data storage, and applies machine learning models for data analysis. The five key components of the framework are wearable sensor-based symptom data collection and uploading, edge (fog) computing, cloud infrastructure, machine learning models for data analysis, and doctors (physicians). The study compares four machine learning techniques: Support Vector Machine (SVM), Artificial Neural Network (ANN), K-Nearest Neighbor (KNN), and Naïve Bayes. SVM outperformed the other algorithms, achieving 98\% training accuracy, 96\% test accuracy, and a 95\% AUC score. Based on the findings, we anticipate that real-time symptom data would enable the proposed system can effectively and accurately diagnose malaria, classifying cases as either Parasitized or Normal.},
	language = {en},
	number = {1},
	urldate = {2025-09-22},
	journal = {Sensing and Imaging},
	author = {Ayalew, Aleka Melese and Admass, Wasyihun Sema and Abuhayi, Biniyam Mulugeta and Negashe, Girma Sisay and Bezabh, Yohannes Agegnehu},
	month = sep,
	year = {2024},
	keywords = {Early identification, Internet of Things, Machine learning, Malaria, Real-time monitoring},
	pages = {55},
}

@article{ayalew_smart_2025,
	title = {Smart {Breast} {Cancer} {Detection}: {Enhancing} {Early} {Breast} {Cancer} {Diagnosis}-{Transitioning} from {Convolutional} {Neural} {Network} to {Involutional} {Neural} {Network} and {Using} {Smart} {Wearable} {Devices}},
	volume = {26},
	issn = {1557-2072},
	shorttitle = {Smart {Breast} {Cancer} {Detection}},
	url = {https://doi.org/10.1007/s11220-025-00561-1},
	doi = {10.1007/s11220-025-00561-1},
	abstract = {Breast cancer is the most prevalent form of tumor in women, and this is the leading cause of mortality in women. Accurately detecting and classifying breast cancer is crucial for effective treatment and diagnosis preparation. Internet of Things (IoT) wearable devices (smart bra) are considered one of the best methods for early detection and, thereby, reducing breast cancer mortality. This study proposes a unique approach for breast cancer classification that combines involutional neural networks (InvNets) with wearable devices to reduce the parameter-intensive nature of convolutional neural networks. Specifically, the involution kernel differs from the convolution kernel because it is location-specific and channel-agnostic. This location-specific operation enhances the network's ability to acquire detailed elements in medical images by adapting to diverse visual patterns across spatial regions. In that regard, magnetic resonance imaging (MRI) has become an important modality for breast cancer detection. This work investigates the use of IoT devices such as wearables and sensors to collect patient health data and monitor changes in breast tissue. If symptoms are present, an MRI scan is performed for a reliable diagnosis of breast cancer utilizing deep learning (InvNets). Our findings show that InvNets achieves 100\% training accuracy, 98.5\% validation accuracy, and 98.6\% testing accuracy after data augmentation, indicating its potential for breast cancer classification. InvNets are highly successful for medical image processing, particularly in circumstances with limited computer resources, as seen by enhanced accuracy and reduced parameter count. As a result, the findings show that InvNets provided consistent and reliable features for breast cancer detection and faster diagnosis.},
	language = {en},
	number = {1},
	urldate = {2025-09-22},
	journal = {Sensing and Imaging},
	author = {Ayalew, Aleka Melese and Oussalah, Mourad and Abuhayi, Biniyam Mulugeta and Bezabh, Yohannes Agegnehu},
	month = mar,
	year = {2025},
	keywords = {Breast cancer, Early detection, InvNets, MRI, Wearable devices},
	pages = {26},
}

@article{ayalew_early-stage_2024,
	title = {Early-stage cardiomegaly detection and classification from {X}-ray images using convolutional neural networks and transfer learning},
	volume = {24},
	issn = {2667-3053},
	url = {https://www.sciencedirect.com/science/article/pii/S2667305324001273},
	doi = {10.1016/j.iswa.2024.200453},
	abstract = {Cardiomyopathy is a serious condition that can result in heart failure, sudden cardiac death, malignant arrhythmias, and thromboembolism. It is a significant contributor to morbidity and mortality globally. The initial finding of cardiomegaly on radiological imaging may signal a deterioration of a known heart condition, an unknown heart disease, or a heart complication related to another illness. Further cardiological evaluation is needed to confirm the diagnosis and determine appropriate treatment. A chest radiograph (X-ray) is the main imaging method used to identify cardiomegaly when the heart is enlarged. A prompt and accurate diagnosis is essential to help healthcare providers determine the most appropriate treatment options before the condition worsens. This study aims to utilize convolutional neural networks and transfer learning techniques, specifically Inception, DenseNet-169, and ResNet-50, to classify cardiomegaly from chest X-ray images automatically. The utilization of block-matching and 3D filtering (BM3D) techniques aimed at enhancing image edge retention, decreasing noise, and utilizing contrast limited adaptive histogram equalization (CLAHE) to enhance contrast in low-intensity images. Gradient-weighted Class Activation Mapping (GradCAM) was used to visualize the significant activation regions contributing to the model's decision. After evaluating all the models, the ResNet-50 model showed outstanding performance. It achieved perfect accuracy of 100 \% in both training, and validation, and an impressive 99.8 \% accuracy in testing. Additionally, it displayed complete 100 \% precision, recall, and F1-score. These findings demonstrate that ResNet-50 surpassed all other models in the study. As a result, the impressive performance of the ResNet-50 model suggests that it could be a valuable tool in improving the efficiency and accuracy of cardiomyopathy diagnosis, ultimately leading to better patient outcomes.},
	urldate = {2025-09-22},
	journal = {Intelligent Systems with Applications},
	author = {Ayalew, Aleka Melese and Enyew, Belay and Bezabh, Yohannes Agegnehu and Abuhayi, Biniyam Mulugeta and Negashe, Girma Sisay},
	month = dec,
	year = {2024},
	keywords = {CNN, Cardiomegaly, Chest X-ray, DenseNet-169, Inception, ResNet-50},
	pages = {200453},
}

@article{ayalew_early-stage_2024-1,
	title = {Early-stage cardiomegaly detection and classification from {X}-ray images using convolutional neural networks and transfer learning},
	volume = {24},
	issn = {2667-3053},
	url = {https://www.sciencedirect.com/science/article/pii/S2667305324001273},
	doi = {10.1016/j.iswa.2024.200453},
	abstract = {Cardiomyopathy is a serious condition that can result in heart failure, sudden cardiac death, malignant arrhythmias, and thromboembolism. It is a significant contributor to morbidity and mortality globally. The initial finding of cardiomegaly on radiological imaging may signal a deterioration of a known heart condition, an unknown heart disease, or a heart complication related to another illness. Further cardiological evaluation is needed to confirm the diagnosis and determine appropriate treatment. A chest radiograph (X-ray) is the main imaging method used to identify cardiomegaly when the heart is enlarged. A prompt and accurate diagnosis is essential to help healthcare providers determine the most appropriate treatment options before the condition worsens. This study aims to utilize convolutional neural networks and transfer learning techniques, specifically Inception, DenseNet-169, and ResNet-50, to classify cardiomegaly from chest X-ray images automatically. The utilization of block-matching and 3D filtering (BM3D) techniques aimed at enhancing image edge retention, decreasing noise, and utilizing contrast limited adaptive histogram equalization (CLAHE) to enhance contrast in low-intensity images. Gradient-weighted Class Activation Mapping (GradCAM) was used to visualize the significant activation regions contributing to the model's decision. After evaluating all the models, the ResNet-50 model showed outstanding performance. It achieved perfect accuracy of 100 \% in both training, and validation, and an impressive 99.8 \% accuracy in testing. Additionally, it displayed complete 100 \% precision, recall, and F1-score. These findings demonstrate that ResNet-50 surpassed all other models in the study. As a result, the impressive performance of the ResNet-50 model suggests that it could be a valuable tool in improving the efficiency and accuracy of cardiomyopathy diagnosis, ultimately leading to better patient outcomes.},
	urldate = {2025-09-22},
	journal = {Intelligent Systems with Applications},
	author = {Ayalew, Aleka Melese and Enyew, Belay and Bezabh, Yohannes Agegnehu and Abuhayi, Biniyam Mulugeta and Negashe, Girma Sisay},
	month = dec,
	year = {2024},
	keywords = {CNN, Cardiomegaly, Chest X-ray, DenseNet-169, Inception, ResNet-50},
	pages = {200453},
}

@article{ruan_tte_2025,
	title = {{TTE}: {Two} {Tokens} {Are} {Enough} to {Improve} {Parameter}-{Efficient} {Tuning}},
	volume = {39},
	issn = {2374-3468, 2159-5399},
	shorttitle = {{TTE}},
	url = {https://ojs.aaai.org/index.php/AAAI/article/view/34226},
	doi = {10.1609/aaai.v39i19.34226},
	abstract = {Existing fine-tuning paradigms are predominantly characterized by Full Parameter Tuning (FPT) and Parameter-Efficient Tuning (PET). FPT fine-tunes all parameters of a pre-trained model on downstream tasks, whereas PET freezes the pre-trained model and employs only a minimal number of learnable parameters for fine-tuning. However, both approaches face issues of overfitting, especially in scenarios where downstream samples are limited. This issue has been thoroughly explored in FPT, but less so in PET. To this end, this paper investigates overfitting in PET, representing a pioneering study in the field. Specifically, across 19 image classification datasets, we employ three classic PET methods (e.g., VPT, Adapter/Adaptformer, and LoRA) and explore various regularization techniques to mitigate overfitting. Regrettably, the results suggest that existing regularization techniques are incompatible with the PET process and may even lead to performance degradation. Consequently, we introduce a new framework named TTE (Two Tokens are Enough), which effectively alleviates overfitting in PET through a novel constraint function based on the learnable tokens. Experiments conducted on 24 datasets across image and few-shot classification tasks demonstrate that our fine-tuning framework not only mitigates overfitting but also significantly enhances PET's performance. Notably, our TTE framework surpasses the highest-performing FPT framework (DR-Tune), utilizing significantly fewer parameters (0.15M vs. 85.84M) and achieving an improvement of 1\%.},
	number = {19},
	urldate = {2025-09-20},
	journal = {Proceedings of the AAAI Conference on Artificial Intelligence},
	author = {Ruan, Jiacheng and Xie, Mingye and Gao, Jingsheng and Gao, Xian and Xiang, Suncheng and Liu, Ting and Fu, Yuzhuo},
	month = apr,
	year = {2025},
	pages = {20209--20217},
}

@misc{jiang_res-tuning_2023,
	title = {Res-{Tuning}: {A} {Flexible} and {Efficient} {Tuning} {Paradigm} via {Unbinding} {Tuner} from {Backbone}},
	copyright = {arXiv.org perpetual, non-exclusive license},
	shorttitle = {Res-{Tuning}},
	url = {https://arxiv.org/abs/2310.19859},
	doi = {10.48550/ARXIV.2310.19859},
	abstract = {Parameter-efficient tuning has become a trend in transferring large-scale foundation models to downstream applications. Existing methods typically embed some light-weight tuners into the backbone, where both the design and the learning of the tuners are highly dependent on the base model. This work offers a new tuning paradigm, dubbed Res-Tuning, which intentionally unbinds tuners from the backbone. With both theoretical and empirical evidence, we show that popular tuning approaches have their equivalent counterparts under our unbinding formulation, and hence can be integrated into our framework effortlessly. Thanks to the structural disentanglement, we manage to free the design of tuners from the network architecture, facilitating flexible combination of various tuning strategies. We further propose a memory-efficient variant of Res-Tuning, where the bypass i.e., formed by a sequence of tuners) is effectively detached from the main branch, such that the gradients are back-propagated only to the tuners but not to the backbone. Such a detachment also allows one-time backbone forward for multi-task inference. Extensive experiments on both discriminative and generative tasks demonstrate the superiority of our method over existing alternatives from the perspectives of efficacy and efficiency. Project page: \${\textbackslash}href\{https://res-tuning.github.io/\}\{{\textbackslash}textit\{https://res-tuning.github.io/\}\}\$.},
	urldate = {2025-09-20},
	publisher = {arXiv},
	author = {Jiang, Zeyinzi and Mao, Chaojie and Huang, Ziyuan and Ma, Ao and Lv, Yiliang and Shen, Yujun and Zhao, Deli and Zhou, Jingren},
	year = {2023},
	note = {Version Number: 1},
	keywords = {Artificial Intelligence (cs.AI), Computer Vision and Pattern Recognition (cs.CV), FOS: Computer and information sciences},
}

@misc{jiang_res-tuning_2023-1,
	title = {Res-{Tuning}: {A} {Flexible} and {Efficient} {Tuning} {Paradigm} via {Unbinding} {Tuner} from {Backbone}},
	shorttitle = {Res-{Tuning}},
	url = {http://arxiv.org/abs/2310.19859},
	doi = {10.48550/arXiv.2310.19859},
	abstract = {Parameter-efficient tuning has become a trend in transferring large-scale foundation models to downstream applications. Existing methods typically embed some light-weight tuners into the backbone, where both the design and the learning of the tuners are highly dependent on the base model. This work offers a new tuning paradigm, dubbed Res-Tuning, which intentionally unbinds tuners from the backbone. With both theoretical and empirical evidence, we show that popular tuning approaches have their equivalent counterparts under our unbinding formulation, and hence can be integrated into our framework effortlessly. Thanks to the structural disentanglement, we manage to free the design of tuners from the network architecture, facilitating flexible combination of various tuning strategies. We further propose a memory-efficient variant of Res-Tuning, where the bypass i.e., formed by a sequence of tuners) is effectively detached from the main branch, such that the gradients are back-propagated only to the tuners but not to the backbone. Such a detachment also allows one-time backbone forward for multi-task inference. Extensive experiments on both discriminative and generative tasks demonstrate the superiority of our method over existing alternatives from the perspectives of efficacy and efficiency. Project page: \${\textbackslash}href\{https://res-tuning.github.io/\}\{{\textbackslash}textit\{https://res-tuning.github.io/\}\}\$.},
	urldate = {2025-09-20},
	publisher = {arXiv},
	author = {Jiang, Zeyinzi and Mao, Chaojie and Huang, Ziyuan and Ma, Ao and Lv, Yiliang and Shen, Yujun and Zhao, Deli and Zhou, Jingren},
	month = oct,
	year = {2023},
	note = {arXiv:2310.19859 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computer Vision and Pattern Recognition},
}

@article{kobayashi_factors_2025,
	title = {Factors ensuring healthy work environments for municipal office workers in the disaster area after the {Fukushima} {Daiichi} nuclear power plant accident: {A} qualitative analysis},
	volume = {116},
	issn = {2212-4209},
	shorttitle = {Factors ensuring healthy work environments for municipal office workers in the disaster area after the {Fukushima} {Daiichi} nuclear power plant accident},
	url = {https://www.sciencedirect.com/science/article/pii/S2212420924008872},
	doi = {10.1016/j.ijdrr.2024.105125},
	abstract = {Previous research has explored the direct impacts of disasters on disaster responders and the factors contributing to their resilience; however, the effects of disasters on responders can persist over the medium to long term. In Japan, municipal office workers play a central role in addressing emergencies during disasters. In the case of the Fukushima Daiichi Nuclear Power Plant accident, over a decade after the disaster, the persistent issue of early retirement and sick leave due to mental health problems, such as depression, remains unresolved. This study aimed to identify the factors that enabled healthy work environments among municipal office workers in disaster-affected areas following this nuclear accident. Semi-structured interviews were conducted with eight employees of Town A, a coastal municipality in Fukushima Prefecture, whose residents, including municipal office workers, were forced to evacuate after the accident. The interview data were analyzed using open coding and subsequently categorized into stages. Results revealed four vulnerability and two resilience factors related to ensuring healthy work environments. These factors were illustrated using a four-quadrant diagram. The vulnerability factors included disorganization in the workplace caused by the disaster, challenges related to professional identity, and organizational culture issues inherent to municipal office workers regardless of the disaster. Meanwhile, the resilience factors identified the expansion of social connections triggered by the disaster and individual stress-coping strategies. When considering support for occupational groups involved in disaster response, it is crucial to account for the medium-to long-term impacts on their work environments and professional identities.},
	urldate = {2025-08-18},
	journal = {International Journal of Disaster Risk Reduction},
	author = {Kobayashi, Akemi and Kobayashi, Tomoyuki and Maeda, Masaharu and Hidaka, Tomoo and Mizuki, Rie},
	month = jan,
	year = {2025},
	keywords = {Burnout, Great East Japan earthquake, Municipal office worker, Nuclear accident, Work environment},
	pages = {105125},
}

@incollection{liao_dynamic_2025,
	address = {New York, NY, USA},
	title = {Dynamic {Adaptation} of {LoRA} {Fine}-{Tuning} for {Efficient} and {Task}-{Specific} {Optimization} of {Large} {Language} {Models}},
	isbn = {979-8-4007-1363-7},
	url = {https://doi.org/10.1145/3730436.3730456},
	abstract = {This paper presents a novel methodology of fine-tuning for large language models-dynamic LoRA. Building from the standard Low-Rank Adaptation framework, this methodology further adds dynamic adaptation mechanisms to improve efficiency and performance. The key contribution of dynamic LoRA lies within its adaptive weight allocation mechanism coupled with an input feature-based adaptive strategy. These enhancements allow for a more precise fine-tuning process that is more tailored to specific tasks. Traditional LoRA methods use static adapter settings, not considering the different importance of model layers. In contrast, dynamic LoRA introduces a mechanism that dynamically evaluates the importance of layer during fine-tuning. This evaluation enables the reallocation of adapter parameters to fit the unique demands of each individual task, which leads to better optimization results. Another gain in flexibility arises from the consideration of the input feature distribution, which helps the model generalize better when faced with complicated and diverse datasets. The joint approach boosts not only the performance over each single task but also the generalization ability of the model. The efficiency of the dynamic LoRA was validated in experiments on benchmark datasets, such as GLUE, with surprising results. More specifically, this method achieved 88.1\% accuracy with an F1-score of 87.3\%. Noticeably, these improvements were made at a slight increase in computational costs: only 0.1\% more resources than standard LoRA. This balance between performance and efficiency positions dynamic LoRA as a practical, scalable solution for fine-tuning LLMs, especially in resource-constrained scenarios. To take it a step further, its adaptability makes it a promising foundation for much more advanced applications, including multimodal tasks.},
	urldate = {2025-08-18},
	booktitle = {Proceedings of the 2025 {International} {Conference} on {Artificial} {Intelligence} and {Computational} {Intelligence}},
	publisher = {Association for Computing Machinery},
	author = {Liao, Xiaoxuan and Wang, Chihang and Zhou, Shicheng and Hu, Jiacheng and Zheng, Hongye and Gao, Jia},
	month = jul,
	year = {2025},
	pages = {120--125},
}

@article{chicco_venus_2025,
	title = {The {Venus} score for the assessment of the quality and trustworthiness of biomedical datasets},
	volume = {18},
	issn = {1756-0381},
	url = {https://doi.org/10.1186/s13040-024-00412-x},
	doi = {10.1186/s13040-024-00412-x},
	abstract = {Biomedical datasets are the mainstays of computational biology and health informatics projects, and can be found on multiple data platforms online or obtained from wet-lab biologists and physicians. The quality and the trustworthiness of these datasets, however, can sometimes be poor, producing bad results in turn, which can harm patients and data subjects. To address this problem, policy-makers, researchers, and consortia have proposed diverse regulations, guidelines, and scores to assess the quality and increase the reliability of datasets. Although generally useful, however, they are often incomplete and impractical. The guidelines of Datasheets for Datasets, in particular, are too numerous; the requirements of the Kaggle Dataset Usability Score focus on non-scientific requisites (for example, including a cover image); and the European Union Artificial Intelligence Act (EU AI Act) sets forth sparse and general data governance requirements, which we tailored to datasets for biomedical AI. Against this backdrop, we introduce our new Venus score to assess the data quality and trustworthiness of biomedical datasets. Our score ranges from 0 to 10 and consists of ten questions that anyone developing a bioinformatics, medical informatics, or cheminformatics dataset should answer before the release. In this study, we first describe the EU AI Act, Datasheets for Datasets, and the Kaggle Dataset Usability Score, presenting their requirements and their drawbacks. To do so, we reverse-engineer the weights of the influential Kaggle Score for the first time and report them in this study. We distill the most important data governance requirements into ten questions tailored to the biomedical domain, comprising the Venus score. We apply the Venus score to twelve datasets from multiple subdomains, including electronic health records, medical imaging, microarray and bulk RNA-seq gene expression, cheminformatics, physiologic electrogram signals, and medical text. Analyzing the results, we surface fine-grained strengths and weaknesses of popular datasets, as well as aggregate trends. Most notably, we find a widespread tendency to gloss over sources of data inaccuracy and noise, which may hinder the reliable exploitation of data and, consequently, research results. Overall, our results confirm the applicability and utility of the Venus score to assess the trustworthiness of biomedical data.},
	language = {en},
	number = {1},
	urldate = {2025-08-18},
	journal = {BioData Mining},
	author = {Chicco, Davide and Fabris, Alessandro and Jurman, Giuseppe},
	month = jan,
	year = {2025},
	keywords = {Bioinformatics, Biomedical data quality, Cheminformatics, Computational biology, Data documentation, Data trustworthiness, Datasheets for Datasets, EU AI Act, Health informatics, Kaggle, Medical data, Medical text, Trustworthiness, Trustworthy data},
	pages = {1},
}

@article{he_pretraining-based_2025,
	title = {Pretraining-based {Relevance}-aware {Visit} {Similarity} {Network} for {Drug} {Recommendation}},
	issn = {2168-2208},
	url = {https://ieeexplore.ieee.org/abstract/document/11084807},
	doi = {10.1109/JBHI.2025.3590391},
	abstract = {Drug recommendation based on electronic health records (EHR) relies heavily on precise patient modeling, which is more complex than conventional recommendation tasks as it requires both temporal modeling of disease progression and referencing similar patients' medication information. However, sparse visit records and vague patient similarity in EHR data pose significant challenges, often introducing noise and ambiguity. To address the above challenges, we propose RaVSNet (Relevance aware Visit Similarity Network), which improves drug recommendation by leveraging both longitudinal and transversal visit similarity and integrating medical relevance knowledge. RaVSNet utilizes multi-dimensional visit information similar to the patient's current visit as a reference, and employs a relevance-aware network to explicitly model the matching relationships between medical conditions and medications. Additionally, RaVSNet designs a general pretraining framework specifically for drug recommendation, including two tasks, Medication Sequence Reconstruction (MSR) and Causal Effect Inference (CEI), to discover the deep connections between medical information and medications. Experimental results on two public EHR datasets, MIMIC-III and MIMIC-IV demonstrate that the proposed algorithm outperforms state-of-the-art methods, yielding more accurate drug recommendation combinations, and the proposed general pretraining framework can be seamlessly integrated into most drug recommendation methods to achieve performance improvements. The implementation is available at: https://github.com/SCUT-CCNL/RaVSNet.},
	urldate = {2025-08-18},
	journal = {IEEE Journal of Biomedical and Health Informatics},
	author = {He, Yichen and Dong, Shoubin and Lin, Yuchen and Zheng, Xiaorou and Hu, Jinlong},
	year = {2025},
	keywords = {Accuracy, Data mining, Data models, Drugs, Electronic health records, Electronic medical records, Focusing, Intelligent healthcare management, MIMICs, Medical diagnostic imaging, Medication recommendations, Patient modeling, Representation learning, Safety},
	pages = {1--14},
}

@article{yang_tcm-gpt_2024,
	title = {{TCM}-{GPT}: {Efficient} pre-training of large language models for domain adaptation in {Traditional} {Chinese} {Medicine}},
	volume = {6},
	issn = {2666-9900},
	shorttitle = {{TCM}-{GPT}},
	url = {https://www.sciencedirect.com/science/article/pii/S2666990024000259},
	doi = {10.1016/j.cmpbup.2024.100158},
	abstract = {Pre-training and fine-tuning have emerged as a promising paradigm across various natural language processing (NLP) tasks. The effectiveness of pretrained large language models (LLM) has witnessed further enhancement, holding potential for applications in the field of medicine, particularly in the context of Traditional Chinese Medicine (TCM). However, the application of these general models to specific domains often yields suboptimal results, primarily due to challenges like lack of domain knowledge, unique objectives, and computational efficiency. Furthermore, their effectiveness in specialized domains, such as Traditional Chinese Medicine, requires comprehensive evaluation. To address the above issues, we propose a novel domain specific TCMDA (TCM Domain Adaptation) approach, efficient pre-training with domain-specific corpus. Specifically, we first construct a large TCM-specific corpus, TCM-Corpus-1B, by identifying domain keywords and retrieving from general corpus. Then, our TCMDA leverages the LoRA which freezes the pretrained model’s weights and uses rank decomposition matrices to efficiently train specific dense layers for pre-training and fine-tuning, efficiently aligning the model with TCM-related tasks, namely TCM-GPT-7B. We further conducted extensive experiments on two TCM tasks, including TCM examination and TCM diagnosis. TCM-GPT-7B archived the best performance across both datasets, outperforming other models by relative increments of 17\% and 12\% in accuracy, respectively. To the best of our knowledge, our study represents the pioneering validation of domain adaptation of a large language model with 7 billion parameters in TCM domain. We will release both TCM-Corpus-1B and TCM-GPT-7B model once accepted to facilitate interdisciplinary development in TCM and NLP, serving as the foundation for further study.},
	urldate = {2025-08-18},
	journal = {Computer Methods and Programs in Biomedicine Update},
	author = {Yang, Guoxing and Liu, Xiaohong and Shi, Jianyu and Wang, Zan and Wang, Guangyu},
	month = jan,
	year = {2024},
	keywords = {Deep learning, Domain adaptation, Large language model, Pretraining, Traditional Chinese Medicine},
	pages = {100158},
}

@article{hijazi_exploring_2025,
	title = {Exploring the impact of interaction dynamics and professional capacity and development on cognitive medical errors: a multiple-case study of healthcare professionals in {Jordan}},
	volume = {25},
	issn = {1472-6920},
	shorttitle = {Exploring the impact of interaction dynamics and professional capacity and development on cognitive medical errors},
	url = {https://doi.org/10.1186/s12909-025-07082-1},
	doi = {10.1186/s12909-025-07082-1},
	abstract = {Addressing cognitve medical errors (MEs) and their contributing factors has emerged as a crucial factor in enhancing patient safety and attaining improved clinical outcomes. This study aimed to examine the impact of interaction dynamics and professional capability and development on cognitive MEs (i.e., mistakes, slips, or lapses) from the perspectives of healthcare professionals in Jordan.},
	language = {en},
	number = {1},
	urldate = {2025-08-18},
	journal = {BMC Medical Education},
	author = {Hijazi, Heba and Alyahya, Mohammad S. and Alolayyan, Main N. and Ajayneh, Farah and Al Abdi, Rabah and Hossain, Ahmed and AlMarzooqi, Alounoud and Alameddine, Mohamad},
	month = apr,
	year = {2025},
	keywords = {Cognitive medical errors, Communication, Continuous medical eduation, TeamSTEPPS, Teamwork, Training},
	pages = {598},
}

@article{wang_parameter-efficient_2025,
	title = {Parameter-efficient fine-tuning in large language models: a survey of methodologies},
	volume = {58},
	issn = {1573-7462},
	shorttitle = {Parameter-efficient fine-tuning in large language models},
	url = {https://doi.org/10.1007/s10462-025-11236-4},
	doi = {10.1007/s10462-025-11236-4},
	abstract = {The large language models, as predicted by scaling law forecasts, have made groundbreaking progress in many fields, particularly in natural language generation tasks, where they have approached or even surpassed human levels. However, the unprecedented scale of their parameters brings significant computational and storage costs. These large language models require substantial computational resources and GPU memory to operate. When adapting large language models to specific downstream tasks, their massive parameter scale poses a significant challenge in fine-tuning on hardware platforms with limited computational power and GPU memory. To address this issue, parameter-efficient fine-tuning (PEFT) offers a practical solution by efficiently adjusting the parameters of large pre-trained models to suit various downstream tasks. Specifically, PEFT adjusts the parameters of pre-trained large language models to adapt to specific tasks or domains, minimizing the introduction of additional parameters and the computational resources required. This review mainly introduces the preliminary knowledge of PEFT, the core ideas and principles of various PEFT algorithms, the applications of PEFT, and potential future research directions. By reading this review, we believe that interested parties can quickly grasp the PEFT methodology, thereby accelerating its development and innovation.},
	language = {en},
	number = {8},
	urldate = {2025-08-18},
	journal = {Artificial Intelligence Review},
	author = {Wang, Luping and Chen, Sheng and Jiang, Linnan and Pan, Shu and Cai, Runze and Yang, Sen and Yang, Fei},
	month = may,
	year = {2025},
	keywords = {Artificial intelligence, Deep learning, Fine-tuning, Large language model, Parameter-efficient},
	pages = {227},
}

@article{german-morales_transfer_2025,
	title = {Transfer {Learning} with {Foundational} {Models} for {Time} {Series} {Forecasting} using {Low}-{Rank} {Adaptations}},
	volume = {123},
	issn = {1566-2535},
	url = {https://www.sciencedirect.com/science/article/pii/S1566253525003203},
	doi = {10.1016/j.inffus.2025.103247},
	abstract = {Foundational Models are an emerging widely used technique of Generative Artificial Intelligence. These models are distinguished by their scalability and the ease with which they can be adapted through the exploitation of Transfer Learning. The availability of high computational power and large datasets have supported their development, achieving a high generalization capacity due to the enormous and heterogeneous amounts of data used in their initial training. These characteristics contribute to a solid base that can be adapted or adjusted to a wide range of tasks, increasing their applicability. This study proposes the methodology LLIAM, a straightforward adaptation of a kind of Foundational Models, Large Language Models, for the Time Series Forecasting task. An adequate time-series prompting schema and Low-Rank Adaptations are used to enhance the knowledge of the model with diverse time series datasets, known as the fine-tuning phase. A study divided in two stages has been performed for evaluating the effectiveness of the proposed methodology. Initially, a comparison was made between the performance of LLIAM and different state-of-the-art Deep Learning algorithms, including Recurrent Neural Networks and Temporal Convolutional Networks, as well as a LLM-based method, TimeLLM. Following this, a zero-shot study is presented in order to evaluate the generalization capacity of the proposed methodology with time series datasets from unknown domains not considered in the model training. The outcomes of this investigation demonstrate the efficacy of LLIAM, highlighting that this straightforward and general approach can attain competent results without the necessity for applying complex modifications. This work also encourages the use of available resources (such as these pre-trained models) and efficient fine-tuning techniques to avoid unnecessary and costly training, narrowing the gap between the goals of traditional Artificial Intelligence and Green Artificial Intelligence.},
	urldate = {2025-08-18},
	journal = {Information Fusion},
	author = {Germán-Morales, M. and Rivera-Rivas, A. J. and del Jesus Díaz, M. J. and Carmona, C. J.},
	month = nov,
	year = {2025},
	keywords = {Foundational Models, Large Language Models, Low-rank Adaptations, Time series forecasting, Transfer Learning},
	pages = {103247},
}

@article{maazallahi_advancing_2025,
	title = {Advancing emotion recognition in social media: {A} novel integration of heterogeneous neural networks with fine-tuned language models},
	volume = {62},
	issn = {0306-4573},
	shorttitle = {Advancing emotion recognition in social media},
	url = {https://www.sciencedirect.com/science/article/pii/S0306457324003339},
	doi = {10.1016/j.ipm.2024.103974},
	abstract = {Social media platforms have emerged as crucial sources for emotion analysis, but the issue of non-compliance in labeling by fine-tuned large language models (LLMs) can significantly impact the accuracy of emotion classification. This study addresses this challenge by introducing a novel compliance-driven training set that systematically harmonizes label discrepancies across multiple LLMs, thereby enhancing classification accuracy by over 5\% on the non-compliance set. Integrating this compliance set with a Heterogeneous Neural Network (HNN) architecture, we propose a robust framework for emotion classification. Our approach is validated on three diverse datasets, GoEmotion, Friends, and TEC, demonstrating substantial improvements in accuracy, F1 score, and recall over baseline models. These results confirm the effectiveness of our compliance-driven strategy and establish a new benchmark for emotion recognition in social media content. The proposed framework offers a versatile and scalable solution applicable across various languages and platforms, ensuring broad utility in advanced emotion classification tasks.},
	number = {2},
	urldate = {2025-08-18},
	journal = {Information Processing \& Management},
	author = {Maazallahi, Abbas and Asadpour, Masoud and Bazmi, Parisa},
	month = mar,
	year = {2025},
	keywords = {Emotion classification, Fine-tuned language models, Heterogeneous neural network, Social media analysis},
	pages = {103974},
}

@article{nowakowski_adapting_2023,
	title = {Adapting multilingual speech representation model for a new, underresourced language through multilingual fine-tuning and continued pretraining},
	volume = {60},
	issn = {0306-4573},
	url = {https://www.sciencedirect.com/science/article/pii/S0306457322002497},
	doi = {10.1016/j.ipm.2022.103148},
	abstract = {In recent years, neural models learned through self-supervised pretraining on large scale multilingual text or speech data have exhibited promising results for underresourced languages, especially when a relatively large amount of data from related language(s) is available. While the technology has a potential for facilitating tasks carried out in language documentation projects, such as speech transcription, pretraining a multilingual model from scratch for every new language would be highly impractical. We investigate the possibility for adapting an existing multilingual wav2vec 2.0 model for a new language, focusing on actual fieldwork data from a critically endangered tongue: Ainu. Specifically, we (i) examine the feasibility of leveraging data from similar languages also in fine-tuning; (ii) verify whether the model’s performance can be improved by further pretraining on target language data. Our results show that continued pretraining is the most effective method to adapt a wav2vec 2.0 model for a new language and leads to considerable reduction in error rates. Furthermore, we find that if a model pretrained on a related speech variety or an unrelated language with similar phonological characteristics is available, multilingual fine-tuning using additional data from that language can have positive impact on speech recognition performance when there is very little labeled data in the target language.},
	number = {2},
	urldate = {2025-08-18},
	journal = {Information Processing \& Management},
	author = {Nowakowski, Karol and Ptaszynski, Michal and Murasaki, Kyoko and Nieuważny, Jagna},
	month = mar,
	year = {2023},
	keywords = {ASR, Automatic speech transcription, Cross-lingual transfer, Endangered languages, Language documentation, Pretrained transformer models, Sakhalin Ainu, Speech representation models, Underresourced languages, Wav2vec 2.0},
	pages = {103148},
}

@article{huang_survey_2025,
	title = {A survey on biomedical automatic text summarization with large language models},
	volume = {62},
	issn = {0306-4573},
	url = {https://www.sciencedirect.com/science/article/pii/S0306457325001578},
	doi = {10.1016/j.ipm.2025.104216},
	abstract = {Automatic text summarization in the biomedical field can support efficient literature screening, medical knowledge management, and innovative medical research. In recent years, Large Language Models (LLMs), as a disruptive technology in natural language processing, have shown great potential for Biomedical Automatic Text Summarization (BATS). This technology helps to better understand the terminology of biomedical texts, track medical hotspots, and generate personalized diagnoses and treatment plans. This paper provides an in-depth discussion on the development of BATS, and the opportunities as well as challenges brought by applying LLMs to biomedical automatic text summarization. Firstly, the development of BATS is reviewed, where traditional text summarization, neural network-based summarization, and LLMs-based summarization are analyzed systematically. Meanwhile, the applications of various LLMs (e.g., BERT and GPT series) in three types of BATS are presented in detail, including extractive summarization, abstractive summarization, and hybrid summarization. Next, the relevant datasets are introduced, such as PubMed, COVID-19 and MIMIC-Ⅲ. Then, traditional, emerging, and auxiliary metrics for evaluating the performance of BATS are shown, and the performance evaluation of different models is elaborated. Finally, the opportunities brought by applying LLMs to BATS are described, and the potential challenges along with the corresponding solutions are discussed.},
	number = {5},
	urldate = {2025-08-18},
	journal = {Information Processing \& Management},
	author = {Huang, Zhenyu and Chen, Xianlai and Wang, Yunbo and Huang, Jincai and Zhao, Xing},
	month = sep,
	year = {2025},
	keywords = {Automatic text summarization, Biomedical, Large language models, Natural language processing, Neural networks},
	pages = {104216},
}

@article{noauthor_survey_2025,
	title = {A survey on biomedical automatic text summarization with large language models},
	volume = {62},
	issn = {0306-4573},
	url = {https://www.sciencedirect.com/science/article/pii/S0306457325001578},
	doi = {10.1016/j.ipm.2025.104216},
	abstract = {Automatic text summarization in the biomedical field can support efficient literature screening, medical knowledge management, and innovative medical …},
	language = {en-US},
	number = {5},
	urldate = {2025-08-18},
	journal = {Information Processing \& Management},
	month = sep,
	year = {2025},
	note = {Publisher: Pergamon},
	pages = {104216},
}

@misc{noauthor_survey_nodate,
	title = {A survey on biomedical automatic text summarization with large language models - {ScienceDirect}},
	url = {https://www.sciencedirect.com/science/article/pii/S0306457325001578},
	urldate = {2025-08-18},
}

@inproceedings{qin_federated_2024,
	address = {Vienna, Austria},
	series = {{ICML}'24},
	title = {Federated full-parameter tuning of billion-sized language models with communication cost under 18 kilobytes},
	volume = {235},
	abstract = {Pre-trained large language models (LLMs) need fine-tuning to improve their responsiveness to natural language instructions. Federated learning offers a way to fine-tune LLMs using the abundant data on end devices without compromising data privacy. Most existing federated fine-tuning methods for LLMs rely on parameter-efficient fine-tuning techniques, which may not reach the performance height possible with full-parameter tuning. However, federated full-parameter tuning of LLMs is a non-trivial problem due to the immense communication cost. This work introduces FedKSeed that employs zeroth-order optimization with a finite set of random seeds. It significantly reduces transmission requirements between the server and clients to just a few random seeds and scalar gradients, amounting to only a few thousand bytes, making federated full-parameter tuning of billion-sized LLMs possible on devices. Building on it, we develop a strategy enabling probability-differentiated seed sampling, prioritizing perturbations with greater impact on model accuracy. Experiments across six scenarios with various LLMs, datasets and data partitions demonstrate that our approach outperforms existing federated LLM fine-tuning methods in both communication efficiency and zero-shot generalization.},
	urldate = {2025-08-18},
	booktitle = {Proceedings of the 41st {International} {Conference} on {Machine} {Learning}},
	publisher = {JMLR.org},
	author = {Qin, Zhen and Chen, Daoyuan and Qian, Bingchen and Ding, Bolin and Li, Yaliang and Deng, Shuiguang},
	month = jul,
	year = {2024},
	pages = {41473--41497},
}

@inproceedings{liu_hift_2024,
	address = {Miami, Florida, USA},
	title = {{HiFT}: {A} {Hierarchical} {Full} {Parameter} {Fine}-{Tuning} {Strategy}},
	shorttitle = {{HiFT}},
	url = {https://aclanthology.org/2024.emnlp-main.1015/},
	doi = {10.18653/v1/2024.emnlp-main.1015},
	abstract = {Full-parameter fine-tuning (FPFT) has become the go-to choice for adapting language models (LMs) to downstream tasks due to its excellent performance. As LMs grow in size, fine-tuning the full parameters of LMs requires a prohibitively large amount of GPU memory. Existing approaches utilize zeroth-order optimizer to conserve GPU memory, which potentially compromises the performance of LMs as non-zero order optimizers tend to converge more readily on most downstream tasks. We propose a novel, memory-efficient, optimizer-independent, end-to-end hierarchical fine-tuning strategy, HiFT, which only updates a subset of parameters at each training step. HiFT significantly reduces the amount of gradients and optimizer state parameters residing in GPU memory at the same time, thereby reducing GPU memory usage. Our results demonstrate that: (1) HiFT achieves comparable performance with parameter-efficient fine-tuning and standard FPFT. (2) Results on six models show that HiFT reduces the number of trainable parameters by about 89.18\% on average compared to FPFT. (3) HiFT supports FPFT of 7B models for 24G GPU memory devices under mixed precision without using any memory saving techniques. (4) HiFT supports various optimizers including AdamW, AdaGrad, SGD, etc. The source code link is https://github.com/misonsky/HiFT.},
	urldate = {2025-08-18},
	booktitle = {Proceedings of the 2024 {Conference} on {Empirical} {Methods} in {Natural} {Language} {Processing}},
	publisher = {Association for Computational Linguistics},
	author = {Liu, YongKang and Zhang, Yiqun and Li, Qian and Liu, Tong and Feng, Shi and Wang, Daling and Zhang, Yifei and Schuetze, Hinrich},
	editor = {Al-Onaizan, Yaser and Bansal, Mohit and Chen, Yun-Nung},
	month = nov,
	year = {2024},
	pages = {18266--18287},
}

@inproceedings{lv_full_2024,
	address = {Bangkok, Thailand},
	title = {Full {Parameter} {Fine}-tuning for {Large} {Language} {Models} with {Limited} {Resources}},
	url = {https://aclanthology.org/2024.acl-long.445/},
	doi = {10.18653/v1/2024.acl-long.445},
	abstract = {Large Language Models (LLMs) have revolutionized Natural Language Processing (NLP) but demand massive GPU resources for training. Lowering the threshold for LLMs training would encourage greater participation from researchers, benefiting both academia and society. While existing approaches have focused on parameter-efficient fine-tuning, which tunes or adds a small number of parameters, few have addressed the challenge of tuning the full parameters of LLMs with limited resources. In this work, we propose a new optimizer, LOw-Memory Optimization (LOMO), which fuses the gradient computation and the parameter update in one step to reduce memory usage. By integrating LOMO with existing memory saving techniques, we reduce memory usage to 10.8\% compared to the standard approach (DeepSpeed solution). Consequently, our approach enables the full parameter fine-tuning of a 65B model on a single machine with 8 {\textbackslash}times RTX 3090, each with 24GB memory. Code and data are available at https://github.com/OpenLMLab/LOMO.},
	urldate = {2025-08-18},
	booktitle = {Proceedings of the 62nd {Annual} {Meeting} of the {Association} for {Computational} {Linguistics} ({Volume} 1: {Long} {Papers})},
	publisher = {Association for Computational Linguistics},
	author = {Lv, Kai and Yang, Yuqing and Liu, Tengxiao and Guo, Qipeng and Qiu, Xipeng},
	editor = {Ku, Lun-Wei and Martins, Andre and Srikumar, Vivek},
	month = aug,
	year = {2024},
	pages = {8187--8198},
}

@article{zhao_multi-granularity_2025,
	title = {A multi-granularity in-context learning method for few-shot {Named} {Entity} {Recognition} via {Knowledgeable} {Parameters} {Fine}-tuning},
	volume = {62},
	issn = {0306-4573},
	url = {https://www.sciencedirect.com/science/article/pii/S0306457325000718},
	doi = {10.1016/j.ipm.2025.104129},
	abstract = {Named Entity Recognition (NER) requires high-quality labeled data for model training, which makes it struggles in real-world scenarios where data is limited. Recently, prompt learning has emerged as a powerful technique that can enhance the NER capabilities of pre-trained models without necessitating large amounts of data. However, existing approaches usually suffer from the challenge of insufficient learning of entities’ semantics and boundary information when utilizing simple prompts. Furthermore, the design of complex prompts can lead to inefficiencies in model inference. In this paper, we propose a Multi-granularity Knowledge-enhanced In-Context learning (MKIC) framework for few-shot NER, employing knowledgeable parameters fine-tuning and boundary discrimination contrastive learning. Specifically, we construct four auxiliary in-context tasks to extract knowledge related to labels, boundaries, and semantics. We also introduce a pluggable Knowledgeable Parameters Fine-tuning (KPF) module that incorporates knowledgeable information into the large language model. In order to keep method lightweight, we only fine-tune the KPF module while keeping the parameters of the language model fixed, which facilitates better knowledge transfer regarding entities. Additionally, we implement an entity-level contrastive learning method to optimize the inter- and intra-token distribution distances. The results of experiments conducted on eight datasets demonstrate that MKIC outperforms current approaches in low-resource settings, achieving 1.08\%–6.18\% improvements in F1 scores over the previous state-of-the-art method, while maintaining comparable performance in typical supervised NER scenarios.},
	number = {4},
	urldate = {2025-08-18},
	journal = {Information Processing \& Management},
	author = {Zhao, Qihui and Gao, Tianhan and Guo, Nan},
	month = jul,
	year = {2025},
	keywords = {Few-shot Named Entity Recognition, In-context learning, Information extraction, Knowledge graph construction, Large language models},
	pages = {104129},
}

@article{saeed_sumex_2024,
	title = {{SUMEX}: {A} hybrid framework for {Semantic} {textUal} {siMilarity} and {EXplanation} generation},
	volume = {61},
	issn = {0306-4573},
	shorttitle = {{SUMEX}},
	url = {https://www.sciencedirect.com/science/article/pii/S0306457324001316},
	doi = {10.1016/j.ipm.2024.103771},
	abstract = {Measuring semantic similarity between two pieces of text is a widely known problem in Natural language processing(NLP). It has many applications, such as finding similar medical notes of patients to accelerate the diagnosis process, plagiarism detection, and document clustering. Most state-of-the-art models are based on machine/deep learning and lack sufficient explanations for their results, limiting their adoption in critical domains like healthcare. This paper presents a hybrid framework SUMEX (Semantic textUal siMilarity and EXplanation generation) that uniquely combines ontology with a state-of-the-art embedding-based model for semantic textual similarity. The primary strength of the framework is that it explains its results in human-understandable natural language, which is vital in critical domains such as healthcare. Experiments have been conducted on two datasets of clinical notes using four embeddings: ScispaCy, BioWord2Vec, ClinicalBERT, and a customized Word2Vec trained on clinical notes. The SUMEX framework outperforms the embedding-based model on the benchmark datasets of ClinicalSTS by improving average precision scores by 7 \% and reducing the false-positives-rate by 23 \%. On the Patients Similarity Dataset, the average top-five and top-three precision scores were improved by 14\% and 10\%, respectively, using SUMEX. The SUMEX also generates explanations for its results in natural language. The domain experts evaluated the quality of the explanations. The results show that the generated explanations are of significantly good quality, with a score of 90 \% and 93 \% for measures of Completeness and Correctness, respectively. In addition, ChatGPT was also used for similarity score and generating explanations. The experiments show that the SUMEX framework performed better than the ChatGPT.},
	number = {5},
	urldate = {2025-08-18},
	journal = {Information Processing \& Management},
	author = {Saeed, Sumaira and Rajput, Quratulain and Haider, Sajjad},
	month = sep,
	year = {2024},
	keywords = {Clinical notes, Embeddings, Explanation generation, Natural language processing, Semantic Textual Similarity(STS), ontology},
	pages = {103771},
}

@article{wang_improving_2024,
	title = {Improving extractive summarization with semantic enhancement through topic-injection based {BERT} model},
	volume = {61},
	issn = {0306-4573},
	url = {https://www.sciencedirect.com/science/article/pii/S0306457324000372},
	doi = {10.1016/j.ipm.2024.103677},
	abstract = {In the field of text summarization, extractive techniques aim to extract key sentences from a document to form a summary. However, traditional methods are not sensitive enough to obtain the core semantics of the text, resulting in summaries that contain complicate comprehension. Recently, topic extraction technology extracts core semantics from text, enabling accurate summaries of the main points of a document. In this paper, we introduce the Topic-Injected Bidirectional Encoder Representations from Transformers (TP-BERT), a novel neural auto-encoder model designed explicitly for extractive summarization. TP-BERT integrates document-related topic words into sentences, improving contextual understanding and more accurately aligning summaries with a document’s main theme, addressing a key shortfall in traditional extractive methods. Another major innovation of TP-BERT is the use of contrastive learning during training. This method enhances summarization efficiency by giving prominence to key sentences and minimizing peripheral information. Additionally, we conducted ablation studies and parameter studies of TP-BERT conducted on the CNN/DailyMail, WikiHow, and XSum datasets. In our two main experiments, the average ROUGE-F1 score improved by 2.69 and 0.45 across the three datasets. In comparison to baseline methods, TP-BERT has demonstrated better performance based on the increase in ROUGE-F1 scores on three datasets. Moreover, the semantic differentiation between sentence representations has also contributed positively to the performance enhancements.},
	number = {3},
	urldate = {2025-08-18},
	journal = {Information Processing \& Management},
	author = {Wang, Yiming and Zhang, Jindong and Yang, Zhiyao and Wang, Bing and Jin, Jingyi and Liu, Yitong},
	month = may,
	year = {2024},
	keywords = {Extractive summarization, Information fusion, Topic model, Transformer},
	pages = {103677},
}

@misc{aali_mimic-iv-ext-bhc_nodate,
	title = {{MIMIC}-{IV}-{Ext}-{BHC}: {Labeled} {Clinical} {Notes} {Dataset} for {Hospital} {Course} {Summarization}},
	shorttitle = {{MIMIC}-{IV}-{Ext}-{BHC}},
	url = {https://physionet.org/content/labelled-notes-hospital-course/1.2.0/},
	doi = {10.13026/5GTE-BV70},
	abstract = {This dataset presents a curated collection of preprocessed and labeled
clinical notes derived from the MIMIC-IV-Note database. The primary aim of
this resource is to facilitate the development and training of machine
learning models focused on summarizing brief hospital courses (BHC) from
clinical discharge notes.

The dataset contains 270,033 meticulously cleaned and standardized clinical
notes containing an average token length of 2,267, ensuring usability for
machine learning (ML) applications. Each clinical note is paired with a
corresponding BHC summary, providing a robust foundation for supervised
learning tasks. The preprocessing pipeline employed uses regular expressions
to address common issues in the raw clinical text, such as special characters,
extraneous whitespace, inconsistent formatting, and irrelevant text, to
produce a high-quality, structured dataset with separated clinical note
sections through appropriate headings.

By offering this resource, we aim to support healthcare professionals and
researchers in their efforts to enhance patient care through the automation of
BHC summarization. This dataset is ideal for exploring various NLP techniques,
developing predictive models, and improving the efficiency and accuracy of
clinical documentation practices. We invite the research community to utilize
this dataset to advance the field of medical informatics and contribute to
better health outcomes.},
	urldate = {2025-08-18},
	publisher = {PhysioNet},
	author = {Aali, Asad and Van Veen, Dave and Arefeen, Yamin and Hom, Jason and Bluethgen, Christian and Reis, Eduardo Pontes and Gatidis, Sergios and Clifford, Namuun and Daws, Joseph and Tehrani, Arash and Kim, Jangwon and Chaudhari, Akshay},
}

@inproceedings{song_hybrid_2021,
	address = {New York, NY, USA},
	series = {{CSAI} '20},
	title = {A {Hybrid} {Model} for {Medical} {Paper} {Summarization} {Based} on {COVID}-19 {Open} {Research} {Dataset}},
	isbn = {978-1-4503-8843-6},
	url = {https://dl.acm.org/doi/10.1145/3445815.3445824},
	doi = {10.1145/3445815.3445824},
	abstract = {Automatic generation of summarization or key phrase has been applied in a variety of domains, such as scientific papers and news. In response to the COVID-19 pandemic, the white house and some research groups have prepared the COVID-19 article dataset. To struggle against the COVID-19, the automatic summarization or key phrase method can be useful for those wanting a quick overview of what the latest information is saying on pandemic topics. This paper introduce the COVID-19 dataset from Kaggle and propose a novel model which combine a conventional Seq2Seq model with attention mechanism and a classical keywords extraction method. Our motivation is to obtain key information and maintain the result coherence. Experiment results reveal that our model depending on the COVID-19 dataset achieves a considerable improvement over a classical Seq2Seq model with attention mechanism.},
	urldate = {2025-08-11},
	booktitle = {Proceedings of the 2020 4th {International} {Conference} on {Computer} {Science} and {Artificial} {Intelligence}},
	publisher = {Association for Computing Machinery},
	author = {Song, Guohui and Wang, Yongbin},
	month = mar,
	year = {2021},
	pages = {52--56},
}

@article{aftiss_biomdsum_2024,
	title = {{BioMDSum}: {An} {Effective} {Hybrid} {Biomedical} {Multi}-{Document} {Summarization} {Method} {Based} on {PageRank} and {Longformer} {Encoder}-{Decoder}},
	volume = {12},
	issn = {2169-3536},
	shorttitle = {{BioMDSum}},
	url = {https://ieeexplore.ieee.org/abstract/document/10788713},
	doi = {10.1109/ACCESS.2024.3514915},
	abstract = {Biomedical multi-document summarization (BioMDSum) involves automatically generating concise and informative summaries from collections of related biomedical documents. While extractive summarization methods have shown promise, they often produce incoherent summaries. Onethe other hand, fully abstractive methods yield coherent summaries but demand extensive training datasets and computational resources due to the typically lengthy nature of biomedical documents. Toeaddress these challenges, weepropose a hybrid summarization method that combines the strengths of both approaches. The proposed method consists of two main phases: (i) an extractive summarization phase that uses k-means clustering to group similar sentences based on their cosine similarity between embeddings generated by the sentence-BERT model, followed by the PageRank algorithm for sentence scoring and selection; and (ii) an abstractive summarization phase that fine-tunes a Longform Encoder-Decoder (LED) transformer model to generate a concise and coherent summary from the sentences selected during the extractive phase. Weeconducted several experiments on the standard biomedical multi-document summarization datasets Cochrane and MS{\textasciicircum}2. The results demonstrate that the proposed method is competitive and outperforms recent state-of-the-art systems based on ROUGE evaluation measures. Specifically, our model achieved ROUGE-1, ROUGE-2, ROUGE-L, BERTScore, and METEOR scores of 29.41\%, 6.57\%, 18.31\%, 85.95\%, and 22.15\% on the Cochrane dataset, and 28.79\%, 8.22\%, 17.93\%, 85.51\%, and 25.17\% on the MS{\textasciicircum}2 dataset, respectively. Furthermore, aneablation analysis shows that integrating extractive and abstractive phases in our hybrid summarization method enhances the overall performance of the proposed approach.},
	urldate = {2025-08-11},
	journal = {IEEE Access},
	author = {Aftiss, Azzedine and Lamsiyah, Salima and Ouatik El Alaoui, Said and Schommer, Christoph},
	year = {2024},
	keywords = {Adaptation models, Biological system modeling, Biomedical multi-document summarization, Computational modeling, Data mining, Hybrid power systems, Itemsets, K-means clustering, Light emitting diodes, PageRank algorithm, Phase transformers, Text summarization, Unified modeling language, hybrid summarization, longformer encoder-decoder, sentence-BERT},
	pages = {188013--188031},
}

@inproceedings{nguyen_hybrid_2021,
	title = {A {Hybrid} {Multi}-answer {Summarization} {Model} for the {Biomedical} {Question}-{Answering} {System}},
	url = {https://ieeexplore.ieee.org/abstract/document/9648640},
	doi = {10.1109/KSE53942.2021.9648640},
	abstract = {In natural language processing problems, text summarization is a difficult problem and always attracts attention from the research community, especially working on biomedical text data which lacks supporting tools and techniques. In this scientific research report, we propose a multi-document summarization model for the responses in the biomedical question and answer system. Our model includes components which is a combination of many advanced techniques as well as some improved methods proposed by authors. We present research methods applied to two main approaches: an extractive summarization architecture based on multi scores and state-of-the-art techniques, presenting our novel prosper-thy-neighbor strategies to improve performance; EAHS model (Extractive-Abstractive hybrid model) based on a denoising auto-encoder for pre-training sequence-to-sequence models (BART). In which we propose a question-driven filtering phase to optimize the selection of the most useful information. Our propose model has achieved positive results with the best ROUGE-1/ROUGE-L scores being the runner-up by ROUGE-2 F1 score by extractive summarization results (over 24 participated teams in MEDIQA2021).},
	urldate = {2025-08-11},
	booktitle = {2021 13th {International} {Conference} on {Knowledge} and {Systems} {Engineering} ({KSE})},
	author = {Nguyen, Quoc-An and Duong, Quoc-Hung and Nguyen, Minh-Quang and Nguyen, Huy-Son and Le, Hoang-Quynh and Can, Duy-Cat and Thanh, Tam Doan and Tran, Mai-Vu},
	month = nov,
	year = {2021},
	note = {ISSN: 2694-4804},
	keywords = {Biological system modeling, Knowledge engineering, Machine learning, Noise reduction, Pipelines, ROUGE, Reproducibility of results, Robustness, biomedical text data, extractive summarization, hybrid summarization model, multi-document summarization, question-driven},
	pages = {1--6},
}

@article{davoodijam_multigbs_2021,
	title = {{MultiGBS}: {A} multi-layer graph approach to biomedical summarization},
	volume = {116},
	issn = {1532-0464},
	shorttitle = {{MultiGBS}},
	url = {https://www.sciencedirect.com/science/article/pii/S1532046421000356},
	doi = {10.1016/j.jbi.2021.103706},
	abstract = {Automatic text summarization methods generate a shorter version of the input text to assist the reader in gaining a quick yet informative gist. Existing text summarization methods generally focus on a single aspect of text when selecting sentences, causing the potential loss of essential information. In this study, we propose a domain-specific method that models a document as a multi-layer graph to enable multiple features of the text to be processed at the same time. The features we used in this paper are word similarity, semantic similarity, and co-reference similarity, which are modelled as three different layers. The unsupervised method selects sentences from the multi-layer graph based on the MultiRank algorithm and the number of concepts. The proposed MultiGBS algorithm employs UMLS and extracts the concepts and relationships using different tools such as SemRep, MetaMap, and OGER. Extensive evaluation by ROUGE and BERTScore shows increased F-measure values.},
	urldate = {2025-08-11},
	journal = {Journal of Biomedical Informatics},
	author = {Davoodijam, Ensieh and Ghadiri, Nasser and Lotfi Shahreza, Maryam and Rinaldi, Fabio},
	month = apr,
	year = {2021},
	keywords = {Automatic text summarization, Concept-based summarization, Domain-specific summary, Multi-graph text modeling, Text mining},
	pages = {103706},
}

@article{rouane_combine_2019,
	title = {Combine clustering and frequent itemsets mining to enhance biomedical text summarization},
	volume = {135},
	issn = {0957-4174},
	url = {https://www.sciencedirect.com/science/article/pii/S0957417419303963},
	doi = {10.1016/j.eswa.2019.06.002},
	abstract = {Text summarization has become an important research area, especially in the biomedical domain, where information overload is a major problem. In this paper, we propose a novel biomedical text summarization system that combines two popular data mining techniques: clustering and frequent itemset mining. Biomedical paper is expressed as a set of biomedical concepts using the UMLS metathesaurus. The K-means algorithm is used to cluster similar sentences. Then, the Apriori algorithm is applied to discover the frequent itemsets among the clustered sentences. Finally, the salient sentences from each cluster are selected to build the summary using the discovered frequent itemsets. For the evaluation step, we selected randomly 100 biomedical papers from the BioMed Central database full-text, and we evaluated the performances of our system by comparing the resulting summaries with the abstracts of these papers using the ROUGE metrics in term of recall, precision, and F-measure. We also compared the obtained summaries with those achieved by five well-known summarizers: TextRank, TextTeaser, SweSum, ItemSet Based Summarizer, Microsoft AutoSummarize, and two baselines: summarization using only the frequent itemsets mining (FRQ-CL), and summarization using only the clustering (CL-FRQ). The results demonstrate that this combination can successfully enhance the summarization performances, and the proposed system outperforms other tested summarizers.},
	urldate = {2025-08-11},
	journal = {Expert Systems with Applications},
	author = {Rouane, Oussama and Belhadef, Hacene and Bouakkaz, Mustapha},
	month = nov,
	year = {2019},
	keywords = {Biomedical concepts, Biomedical text summarization, Clustering, Frequent itemsets mining, ROUGE metrics},
	pages = {362--373},
}

@inproceedings{yongkiatpanich_extractive_2019,
	address = {Singapore},
	title = {Extractive {Text} {Summarization} {Using} {Ontology} and {Graph}-{Based} {Method}},
	copyright = {https://ieeexplore.ieee.org/Xplorehelp/downloads/license-information/IEEE.html},
	isbn = {978-1-7281-1322-7},
	url = {https://ieeexplore.ieee.org/document/8821755/},
	doi = {10.1109/CCOMS.2019.8821755},
	urldate = {2025-08-11},
	booktitle = {2019 {IEEE} 4th {International} {Conference} on {Computer} and {Communication} {Systems} ({ICCCS})},
	publisher = {IEEE},
	author = {Yongkiatpanich, Chuleepohn and Wichadakul, Duangdao},
	month = feb,
	year = {2019},
	pages = {105--110},
}

@inproceedings{yongkiatpanich_extractive_2019-1,
	title = {Extractive {Text} {Summarization} {Using} {Ontology} and {Graph}-{Based} {Method}},
	url = {https://ieeexplore.ieee.org/abstract/document/8821755},
	doi = {10.1109/CCOMS.2019.8821755},
	abstract = {In recent years, many people started to take care of the physical health. The biomedical article is the trendy issue at the moment leading to the huge amount of knowledge created rapidly. In this paper, we propose a new automatic extractive text summarization technique based on graph representation that makes use of the Unified Medical Language System (UMLS), an ontology knowledge from the National Library of Medicine (NLM). We combined the graph building rules with a distance function between text documents, called Word Mover's Distance. To prioritize the core sentences, we extracted the summary by using a popular graph-based method from Google, PageRank. We compared our results with other text summarization software using 400 biological review papers as a corpus randomly sampled from PubMed Central. Our approach outperformed the baseline comparators in terms of Recall-Oriented Understudy for Gisting Evaluation (ROUGE) scores.},
	urldate = {2025-08-11},
	booktitle = {2019 {IEEE} 4th {International} {Conference} on {Computer} and {Communication} {Systems} ({ICCCS})},
	author = {Yongkiatpanich, Chuleepohn and Wichadakul, Duangdao},
	month = feb,
	year = {2019},
	keywords = {Biomedical measurement, Gold, Ontologies, PageRank, Standards, Task analysis, UMLS, Unified modeling language, XML, biomedical, extractive summarization, graph-based method, ontology, text summarization, word mover’s distance (WMD)},
	pages = {105--110},
}

@article{luo_chatgpt_2025,
	title = {{ChatGPT} based contrastive learning for radiology report summarization},
	volume = {267},
	issn = {0957-4174},
	url = {https://www.sciencedirect.com/science/article/pii/S0957417424026940},
	doi = {10.1016/j.eswa.2024.125827},
	abstract = {Automatically Impression Generation (AIG) can conclude essential information of the “Findings” section, thus facilitating more effective communication between radiographers and physicians. Different from general abstractive summarization, AIG is more challenging for data-driven neural models. This may be due to two critical issues: the serious data bias and the shallow and rough use of available data. To alleviate data bias problem and make best use of available data, we propose a novel ChatGPT based Contrastive Learning (CCL) approach. Specifically, CCL progressively learns to generate impressions to address the above problems. Firstly, we input “findings” and its target “impression” into T5 for fine-tuning, namely WarmUp; Secondly, we propose CCL to alleviate exposure bias by adding its self-generation as negative samples, and treat all negative samples differently according to their sample quality. This can make full use of the available limited data; Thirdly, we select the non-dominant data in data bias by assessing model and input them into ChatGPT for data augmentation. By iteratively doing the second step and third step, CCL can gradually improve its summarization performance on radiology reports. Obtained results on the public OpenI and MIMIC-CXR datasets show effectiveness of our CCL.22https://github.com/jzw1234/Chataug-CCL.},
	urldate = {2025-08-06},
	journal = {Expert Systems with Applications},
	author = {Luo, Zhenjie and Jiang, Zuowei and Wang, Mingyang and Cai, Xiaoyan and Gao, Dehong and Yang, Libin},
	month = apr,
	year = {2025},
	keywords = {ChatGPT, Contrastive learning, Radiology reports, Text summarization},
	pages = {125827},
}

@article{zhang_out--distribution_2025,
	title = {Out-of-distribution detection under the paradigm of pre-training and fine-tuning: {A} regularization-based approach},
	volume = {294},
	issn = {0957-4174},
	shorttitle = {Out-of-distribution detection under the paradigm of pre-training and fine-tuning},
	url = {https://www.sciencedirect.com/science/article/pii/S0957417425023772},
	doi = {10.1016/j.eswa.2025.128759},
	abstract = {While fine-tuning pre-trained models has become standard practice for downstream tasks, we reveal an important yet overlooked trade-off: the process of optimizing for task accuracy often degrades the model’s ability to detect out-of-distribution (OOD) samples. To address this limitation, we propose a novel regularization approach that preserves the pre-trained model’s generalization capabilities during fine-tuning. Our method constrains the representation drift in the penultimate layer through a Smooth L1 loss, maintaining the original model’s beneficial properties while still allowing necessary adaptation to the target task - particularly effective in challenging scenarios with significant in-distribution/out-of-distribution similarity. Theoretical analysis demonstrates this approach bounds the feature space transformation, while experimental results across multiple benchmarks confirm its ability to maintain model reliability without compromising accuracy.},
	urldate = {2025-08-06},
	journal = {Expert Systems with Applications},
	author = {Zhang, Jinsong and Fu, Qiang and Chen, Xu and Han, Shi},
	month = dec,
	year = {2025},
	keywords = {OOD Detection, fine-tuning, regularization},
	pages = {128759},
}

@article{park_query-focused_2024,
	title = {Query-focused summarization with the context-graph information fusion transformer},
	volume = {241},
	issn = {0957-4174},
	url = {https://www.sciencedirect.com/science/article/pii/S0957417423032013},
	doi = {10.1016/j.eswa.2023.122699},
	abstract = {Query-Focused Summarization (QFS) is a system that understands important information from a long document and generates them as a summary that can responds to the query. In QFS, how to properly utilize query information to generate a summary is a challenging problem. Existing Transformer-based QFS models, which is attending all words in the concatenation of a query and a document, result in inaccurate concentration on some unimportant words and they consequently cannot generate a good query-focused summary. This study proposes a Query-attentive Semantic Graph (QSG) that assists in identifying words related to the query, and a novel QFS model that generates a query-focused summary by appropriately fusing the contextual information of the language model with the structural information of QSG. In addition, we propose a novel personalized PageRank based graph neural network that computes each node’s importance score for the query inside QSG and utilizes it for node representation calculation. Experimental results on two QFS benchmarks show that the performance of the proposed model outperforms the simple Transformer-based model by large margins, as well as other state-of-the-art QFS.},
	urldate = {2025-08-06},
	journal = {Expert Systems with Applications},
	author = {Park, Choongwon and Ko, Youngjoong},
	month = may,
	year = {2024},
	keywords = {Graph neural networks, Graph-based method, Query-focused summarization},
	pages = {122699},
}

@article{van_yperen_lats_2025,
	title = {{LATS}: {Low} resource abstractive text summarization},
	volume = {286},
	issn = {0957-4174},
	shorttitle = {{LATS}},
	url = {https://www.sciencedirect.com/science/article/pii/S0957417425016999},
	doi = {10.1016/j.eswa.2025.128078},
	abstract = {Text summarization is an increasingly crucial focus of Natural Language Processing (NLP), and state-of-the-art models such as PEGASUS have demonstrated remarkable potential to ever more efficient and accurate abstractive summarization. Nonetheless, recent developments of deep learning models that focus on training with large datasets can become at risk of sub-optimal generalization, inefficient training time, and can get stuck at local optima due to high-dimensional non-convex optimization domains. Current research in the field of NLP suggests that leveraging curriculum learning techniques to guide model training (enabling the model to learn from training data with increasing difficulty) could provide a means to achieve enhanced model performance. In this paper we investigate the effectiveness of curriculum learning strategies and data augmentation techniques on PEGASUS to increase performance with low-resource training data from the CNN/DM dataset. We introduce a novel text-summary pair complexity scoring algorithm along with two simple baseline difficulty measures. We find that our novel complexity sorting method consistently outperforms the baseline sorting methods and boosts performance of PEGASUS. The Baby-Steps curriculum learning strategy with this sorting method leads to performance improvements of 5.65 \%, from a combined ROUGE F1-score of 83.28 to 87.99. When this strategy is combined with a data augmentation technique, Easy Data Augmentation, this leads to an improvement to 6.54 \%. These statistics are relative to a baseline without curriculum learning or data augmentation.},
	urldate = {2025-08-06},
	journal = {Expert Systems with Applications},
	author = {van Yperen, Chris and Frasincar, Flavius and El Kanfoudi, Kamilah},
	month = aug,
	year = {2025},
	keywords = {Abstractive text summarization, Complexity scoring, Curriculum learning, Low-resource summarization},
	pages = {128078},
}

@article{liu_automatic_2024,
	title = {Automatic {Text} {Summarization} {Method} {Based} on {Improved} {TextRank} {Algorithm} and {K}-{Means} {Clustering}},
	volume = {287},
	issn = {0950-7051},
	url = {https://www.sciencedirect.com/science/article/pii/S0950705124000820},
	doi = {10.1016/j.knosys.2024.111447},
	abstract = {Automatic text summarization is to obtain a summary by compressing the text while retaining its important information. Then users can obtain the important content of the text by reading the summary. In the research literatures, the extraction summary method is widely used and is also one type of the main research methods of summary methods. However, this extraction summary method still has some problems. The selection of the initial cluster center has not been carefully determined, and the sentence redundancy summarized is high in articles with complex sentences. In order to solve the above problems, this paper proposes an automatic text summarization method based on improved TextRank algorithm and K-Means clustering. This method combines the improved BM25 model and the TextRank algorithm to calculate the BM25 similarity between sentences and obtain the TR scores of sentences. The TR scores are used to select the initial center of clustering based on similarity difference judgment and maximum judgment. The final summary is obtained by combining the cluster scores and sentence scores. The experimental results show that the proposed method in this paper has better evaluation indicators containing ROUGE-1, ROUGE-2 and ROUGE-L than other comparison algorithms including Lead-3, TextRank and MBM25EMB on the DUC2004 dataset. In conclusion, the proposed method in this paper improves the accuracy of automatic text summarization and reduce the redundancy from documents.},
	urldate = {2025-08-06},
	journal = {Knowledge-Based Systems},
	author = {Liu, Wenjun and Sun, Yuyan and Yu, Bao and Wang, Hailan and Peng, Qingcheng and Hou, Mengshu and Guo, Huan and Wang, Hai and Liu, Cheng},
	month = mar,
	year = {2024},
	keywords = {K-means Clustering, Sentence Vector, Text Summarization, TextRank Algorithm, Word Embedding},
	pages = {111447},
}

@article{liu_dscisum_2025,
	title = {{DSciSum}: {Detailed} summarization of long scientific documents},
	volume = {317},
	issn = {0950-7051},
	shorttitle = {{DSciSum}},
	url = {https://www.sciencedirect.com/science/article/pii/S0950705125004563},
	doi = {10.1016/j.knosys.2025.113409},
	abstract = {A summary is frequently considered by academics as a viable alternative to long scientific documents. Prior studies generally required well-annotated training datasets such as arXiv and PubMed, using abstracts from articles as supervised signals. However, these gold summaries merely provide a cursory overview of the subject matter, lacking crucial detailed information, such as datasets, evaluation metrics and model performance, which are essential for both academics and the general public. To address this problem, we propose DSciSum, an extract-then-generate framework that utilizes the zero-shot capabilities and a superior semantic understanding of large language models (LLMs). This approach focuses on previously overlooked details, thereby generating more human-related summaries. Moreover, an innovative LLM-based evaluation criterion is designed as a substitute for traditional metrics, providing a more meaningful and professional assessment for scientific summarization. Specifically, DSciSum first selects salient sentences containing both general and detailed information using a statistics-based heuristic approach. Thereafter, it pretrains and finetunes LLMs to acquire the generator tailored for scientific summarization. Finally, G-SciEval is designed to provide a human-related evaluation of scientific summarization from a deep semantic perspective. Experimental results show that DSciSum outperforms both the reference and state-of-the-art models on arXivCap.},
	urldate = {2025-08-06},
	journal = {Knowledge-Based Systems},
	author = {Liu, Ran and Mao, Xian-Ling and Huang, Heyan},
	month = may,
	year = {2025},
	keywords = {Automatic text summarization, Evaluation, Large language models, Long document summarization},
	pages = {113409},
}

@article{wang_dynamic_2025,
	title = {Dynamic data selection with normalized gradient-based influence approximation for targeted fine-tuning of {LLMs}},
	volume = {327},
	issn = {0950-7051},
	url = {https://www.sciencedirect.com/science/article/pii/S0950705125011852},
	doi = {10.1016/j.knosys.2025.114144},
	abstract = {Selecting suitable data yields increasing importance for Supervised Fine-Tuning (SFT) of large language models, efficiently enhancing their performance on specific tasks. To this end, gradient-based selection methods via influence approximation offer promising solutions by estimating how individual training data samples affect the target task loss. However, previous studies implicitly reveal that classic one-step gradient-based selection methods suffer from both selection length bias and decreasing long-time selection effectiveness. In this paper, we perform theoretical and empirical analysis to systematically investigate these two issues: (1) the selection length bias is caused by the negative correlation between the influence approximation and the lengths of the sample completion, which is introduced by the cumulative effect of token gradient norms; (2) the decreasing long-time selection effectiveness lies in the decreasing correlation between the one-step influence approximation and the targeted task loss optimization during the long training process. To address these issues, we further propose a dynamic normalized gradient-based data selection framework, where the selected data coreset is continuously updated based on recomputed influence scores with normalized gradients. Extensive experimental results verify our analysis, indicating that dynamic selection is better than static selection in loss optimization, targeting the model’s general, mathematical, or coding abilities. Meanwhile, our proposed framework also outperforms the state-of-the-art method in performance enhancement.},
	urldate = {2025-08-06},
	journal = {Knowledge-Based Systems},
	author = {Wang, Zige and Zhu, Qi and Mi, Fei and Wang, Yasheng and Wang, Haotian and Shang, Lifeng},
	month = oct,
	year = {2025},
	keywords = {Dynamic data selection, Gradient-based data influence approximation, Large language models, Targeted fine-tuning},
	pages = {114144},
}

@misc{hu_lora_2021-1,
	title = {{LoRA}: {Low}-{Rank} {Adaptation} of {Large} {Language} {Models}},
	shorttitle = {{LoRA}},
	url = {http://arxiv.org/abs/2106.09685},
	doi = {10.48550/arXiv.2106.09685},
	abstract = {An important paradigm of natural language processing consists of large-scale pre-training on general domain data and adaptation to particular tasks or domains. As we pre-train larger models, full fine-tuning, which retrains all model parameters, becomes less feasible. Using GPT-3 175B as an example -- deploying independent instances of fine-tuned models, each with 175B parameters, is prohibitively expensive. We propose Low-Rank Adaptation, or LoRA, which freezes the pre-trained model weights and injects trainable rank decomposition matrices into each layer of the Transformer architecture, greatly reducing the number of trainable parameters for downstream tasks. Compared to GPT-3 175B fine-tuned with Adam, LoRA can reduce the number of trainable parameters by 10,000 times and the GPU memory requirement by 3 times. LoRA performs on-par or better than fine-tuning in model quality on RoBERTa, DeBERTa, GPT-2, and GPT-3, despite having fewer trainable parameters, a higher training throughput, and, unlike adapters, no additional inference latency. We also provide an empirical investigation into rank-deficiency in language model adaptation, which sheds light on the efficacy of LoRA. We release a package that facilitates the integration of LoRA with PyTorch models and provide our implementations and model checkpoints for RoBERTa, DeBERTa, and GPT-2 at https://github.com/microsoft/LoRA.},
	urldate = {2025-07-08},
	publisher = {arXiv},
	author = {Hu, Edward J. and Shen, Yelong and Wallis, Phillip and Allen-Zhu, Zeyuan and Li, Yuanzhi and Wang, Shean and Wang, Lu and Chen, Weizhu},
	month = oct,
	year = {2021},
	note = {arXiv:2106.09685 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computation and Language, Computer Science - Machine Learning},
}

@misc{hu_lora_2021-2,
	title = {{LoRA}: {Low}-{Rank} {Adaptation} of {Large} {Language} {Models}},
	shorttitle = {{LoRA}},
	url = {http://arxiv.org/abs/2106.09685},
	doi = {10.48550/arXiv.2106.09685},
	abstract = {An important paradigm of natural language processing consists of large-scale pre-training on general domain data and adaptation to particular tasks or domains. As we pre-train larger models, full fine-tuning, which retrains all model parameters, becomes less feasible. Using GPT-3 175B as an example -- deploying independent instances of fine-tuned models, each with 175B parameters, is prohibitively expensive. We propose Low-Rank Adaptation, or LoRA, which freezes the pre-trained model weights and injects trainable rank decomposition matrices into each layer of the Transformer architecture, greatly reducing the number of trainable parameters for downstream tasks. Compared to GPT-3 175B fine-tuned with Adam, LoRA can reduce the number of trainable parameters by 10,000 times and the GPU memory requirement by 3 times. LoRA performs on-par or better than fine-tuning in model quality on RoBERTa, DeBERTa, GPT-2, and GPT-3, despite having fewer trainable parameters, a higher training throughput, and, unlike adapters, no additional inference latency. We also provide an empirical investigation into rank-deficiency in language model adaptation, which sheds light on the efficacy of LoRA. We release a package that facilitates the integration of LoRA with PyTorch models and provide our implementations and model checkpoints for RoBERTa, DeBERTa, and GPT-2 at https://github.com/microsoft/LoRA.},
	urldate = {2025-07-04},
	publisher = {arXiv},
	author = {Hu, Edward J. and Shen, Yelong and Wallis, Phillip and Allen-Zhu, Zeyuan and Li, Yuanzhi and Wang, Shean and Wang, Lu and Chen, Weizhu},
	month = oct,
	year = {2021},
	note = {arXiv:2106.09685 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computation and Language, Computer Science - Machine Learning},
}

@misc{noauthor_low-rank_nodate,
	title = {Low-{Rank} {Adaptation} for {Foundation} {Models}: {A} {Comprehensive} {Review}},
	url = {https://arxiv.org/html/2501.00365v1},
	urldate = {2025-07-04},
}

@misc{noauthor_pre-training_nodate,
	title = {Pre-training {Everywhere}: {Parameter}-{Efficient} {Fine}-{Tuning} for {Medical} {Image} {Analysis} via {Target} {Parameter} {Pre}-training},
	url = {https://arxiv.org/html/2408.15011v1},
	urldate = {2025-07-04},
}

@article{abou_baker_parameter-efficient_2024,
	title = {Parameter-{Efficient} {Fine}-{Tuning} of {Large} {Pretrained} {Models} for {Instance} {Segmentation} {Tasks}},
	volume = {6},
	copyright = {http://creativecommons.org/licenses/by/3.0/},
	issn = {2504-4990},
	url = {https://www.mdpi.com/2504-4990/6/4/133},
	doi = {10.3390/make6040133},
	abstract = {Research and applications in artificial intelligence have recently shifted with the rise of large pretrained models, which deliver state-of-the-art results across numerous tasks. However, the substantial increase in parameters introduces a need for parameter-efficient training strategies. Despite significant advancements, limited research has explored parameter-efficient fine-tuning (PEFT) methods in the context of transformer-based models for instance segmentation. Addressing this gap, this study investigates the effectiveness of PEFT methods, specifically adapters and Low-Rank Adaptation (LoRA), applied to two models across four benchmark datasets. Integrating sequentially arranged adapter modules and applying LoRA to deformable attention—explored here for the first time—achieves competitive performance while fine-tuning only about 1–6\% of model parameters, a marked improvement over the 40–55\% required in traditional fine-tuning. Key findings indicate that using 2–3 adapters per transformer block offers an optimal balance of performance and efficiency. Furthermore, LoRA, exhibits strong parameter efficiency when applied to deformable attention, and in certain cases surpasses adapter configurations. These results show that the impact of PEFT techniques varies based on dataset complexity and model architecture, underscoring the importance of context-specific tuning. Overall, this work demonstrates the potential of PEFT to enable scalable, customizable, and computationally efficient transfer learning for instance segmentation tasks.},
	language = {en},
	number = {4},
	urldate = {2025-07-04},
	journal = {Machine Learning and Knowledge Extraction},
	author = {Abou Baker, Nermeen and Rohrschneider, David and Handmann, Uwe},
	month = dec,
	year = {2024},
	note = {Number: 4
Publisher: Multidisciplinary Digital Publishing Institute},
	keywords = {LoRA, MASK DINO, PEFT, SEEM, adapters, finetuning, instance segmentation},
	pages = {2783--2807},
}

@article{tu_overview_2024,
	title = {An overview of large {AI} models and their applications},
	volume = {2},
	issn = {2731-9008},
	url = {https://doi.org/10.1007/s44267-024-00065-8},
	doi = {10.1007/s44267-024-00065-8},
	abstract = {In recent years, large-scale artificial intelligence (AI) models have become a focal point in technology, attracting widespread attention and acclaim. Notable examples include Google’s BERT and OpenAI’s GPT, which have scaled their parameter sizes to hundreds of billions or even tens of trillions. This growth has been accompanied by a significant increase in the amount of training data, significantly improving the capabilities and performance of these models. Unlike previous reviews, this paper provides a comprehensive discussion of the algorithmic principles of large-scale AI models and their industrial applications from multiple perspectives. We first outline the evolutionary history of these models, highlighting milestone algorithms while exploring their underlying principles and core technologies. We then evaluate the challenges and limitations of large-scale AI models, including computational resource requirements, model parameter inflation, data privacy concerns, and specific issues related to multi-modal AI models, such as reliance on text-image pairs, inconsistencies in understanding and generation capabilities, and the lack of true “multi-modality”. Various industrial applications of these models are also presented. Finally, we discuss future trends, predicting further expansion of model scale and the development of cross-modal fusion. This study provides valuable insights to inform and inspire future future research and practice.},
	language = {en},
	number = {1},
	urldate = {2025-07-04},
	journal = {Visual Intelligence},
	author = {Tu, Xiaoguang and He, Zhi and Huang, Yi and Zhang, Zhi-Hao and Yang, Ming and Zhao, Jian},
	month = dec,
	year = {2024},
	keywords = {Artificial Intelligence, Artificial intelligence, Big Data, Computational Intelligence, GPT, Large AI models, Large language models, Logic in AI, Machine Learning, Symbolic AI},
	pages = {34},
}

@misc{li_revisiting_2024,
	title = {Revisiting {Catastrophic} {Forgetting} in {Large} {Language} {Model} {Tuning}},
	url = {http://arxiv.org/abs/2406.04836},
	doi = {10.48550/arXiv.2406.04836},
	abstract = {Catastrophic Forgetting (CF) means models forgetting previously acquired knowledge when learning new data. It compromises the effectiveness of large language models (LLMs) during fine-tuning, yet the underlying causes have not been thoroughly investigated. This paper takes the first step to reveal the direct link between the flatness of the model loss landscape and the extent of CF in the field of LLMs. Based on this, we introduce the sharpness-aware minimization to mitigate CF by flattening the loss landscape. Experiments on three widely-used fine-tuning datasets, spanning different model scales, demonstrate the effectiveness of our method in alleviating CF. Analyses show that we nicely complement the existing anti-forgetting strategies, further enhancing the resistance of LLMs to CF.},
	urldate = {2025-07-04},
	publisher = {arXiv},
	author = {Li, Hongyu and Ding, Liang and Fang, Meng and Tao, Dacheng},
	month = jun,
	year = {2024},
	note = {arXiv:2406.04836 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computation and Language},
}

@misc{noauthor_fine-tuning_nodate,
	title = {Fine-{Tuning} and {Deploying} {Large} {Language} {Models} {Over} {Edges}: {Issues} and {Approaches}},
	url = {https://arxiv.org/html/2408.10691v1},
	urldate = {2025-07-04},
}

@article{pratap_fine_2025,
	title = {The fine art of fine-tuning: {A} structured review of advanced {LLM} fine-tuning techniques},
	volume = {11},
	issn = {2949-7191},
	shorttitle = {The fine art of fine-tuning},
	url = {https://www.sciencedirect.com/science/article/pii/S2949719125000202},
	doi = {10.1016/j.nlp.2025.100144},
	abstract = {Transformer-based models have consistently demonstrated superior accuracy compared to various traditional models across a range of downstream tasks. However, due to their large nature, training or fine-tuning them for specific tasks has heavy computational and memory demands. This causes the creation of specialized transformer-based models to be almost impossible in the generally present constrained scenarios. To tackle this issue and to make these large models more accessible, a plethora of techniques have been developed. In this study, we will be reviewing the types of techniques developed, their impacts and benefits concerning performance and resource usage along with the latest developments in the domain. We have broadly categorized these techniques into six key areas: Changes in Training Method, Changes in Adapter, Quantization, Parameter Selection, Mixture of Experts, and Application based methods. We collated the results of various techniques on common benchmarks and also evaluated their performance on different datasets and base models.},
	urldate = {2025-07-04},
	journal = {Natural Language Processing Journal},
	author = {Pratap, Samar and Aranha, Alston Richard and Kumar, Divyanshu and Malhotra, Gautam and Iyer, Anantharaman Palacode Narayana and S.s., Shylaja},
	month = jun,
	year = {2025},
	keywords = {Adapter, FFT, LLM, LoRA, MoE, PEFT, Quantization},
	pages = {100144},
}

@inproceedings{liao_parameter-efficient_2023,
	address = {Toronto, Canada},
	title = {Parameter-{Efficient} {Fine}-{Tuning} without {Introducing} {New} {Latency}},
	url = {https://aclanthology.org/2023.acl-long.233/},
	doi = {10.18653/v1/2023.acl-long.233},
	abstract = {Parameter-efficient fine-tuning (PEFT) of pre-trained language models has recently demonstrated remarkable achievements, effectively matching the performance of full fine-tuning while utilizing significantly fewer trainable parameters, and consequently addressing the storage and communication constraints. Nonetheless, various PEFT methods are limited by their inherent characteristics. In the case of sparse fine-tuning, which involves modifying only a small subset of the existing parameters, the selection of fine-tuned parameters is task- and domain-specific, making it unsuitable for federated learning. On the other hand, PEFT methods with adding new parameters typically introduce additional inference latency. In this paper, we demonstrate the feasibility of generating a sparse mask in a task-agnostic manner, wherein all downstream tasks share a common mask. Our approach, which relies solely on the magnitude information of pre-trained parameters, surpasses existing methodologies by a significant margin when evaluated on the GLUE benchmark. Additionally, we introduce a novel adapter technique that directly applies the adapter to pre-trained parameters instead of the hidden representation, thereby achieving identical inference speed to that of full fine-tuning. Through extensive experiments, our proposed method attains a new state-of-the-art outcome in terms of both performance and storage efficiency, storing only 0.03\% parameters of full fine-tuning.},
	urldate = {2025-07-04},
	booktitle = {Proceedings of the 61st {Annual} {Meeting} of the {Association} for {Computational} {Linguistics} ({Volume} 1: {Long} {Papers})},
	publisher = {Association for Computational Linguistics},
	author = {Liao, Baohao and Meng, Yan and Monz, Christof},
	editor = {Rogers, Anna and Boyd-Graber, Jordan and Okazaki, Naoaki},
	month = jul,
	year = {2023},
	pages = {4242--4260},
}

@article{alves_benchmarking_2025,
	title = {A benchmarking framework and dataset for learning to defer in human-{AI} decision-making},
	volume = {12},
	copyright = {2025 The Author(s)},
	issn = {2052-4463},
	url = {https://www.nature.com/articles/s41597-025-04664-y},
	doi = {10.1038/s41597-025-04664-y},
	abstract = {Learning to Defer (L2D) algorithms improve human-AI collaboration by deferring decisions to human experts when they are likely to be more accurate than the AI model. These can be crucial in high-stakes tasks like fraud detection, where false negatives can cost victims their life savings. The primary challenge in training and evaluating these systems is the high cost of acquiring expert predictions, often leading to the use of simplistic simulated expert behavior in benchmarks. We introduce OpenL2D, a framework generating synthetic experts with adjustable decision-making processes and work capacity constraints for more realistic L2D testing. Applied to a public fraud detection dataset, OpenL2D creates the financial fraud alert review dataset (FiFAR), which contains predictions from 50 fraud analysts for 30 K instances. We show that FiFAR’s synthetic experts are similar to real experts in metrics such as consistency and inter-expert agreement. Our L2D benchmark reveals that performance rankings of L2D algorithms vary significantly based on the available experts, highlighting the need to consider diverse expert behavior in L2D benchmarking.},
	language = {en},
	number = {1},
	urldate = {2025-07-04},
	journal = {Scientific Data},
	author = {Alves, Jean V. and Leitão, Diogo and Jesus, Sérgio and Sampaio, Marco O. P. and Liébana, Javier and Saleiro, Pedro and Figueiredo, Mário A. T. and Bizarro, Pedro},
	month = apr,
	year = {2025},
	note = {Publisher: Nature Publishing Group},
	keywords = {Computer science, Scientific data},
	pages = {506},
}

@article{luo_pre-trained_2024,
	title = {Pre-trained language models in medicine: {A} survey},
	volume = {154},
	issn = {0933-3657},
	shorttitle = {Pre-trained language models in medicine},
	url = {https://www.sciencedirect.com/science/article/pii/S0933365724001465},
	doi = {10.1016/j.artmed.2024.102904},
	abstract = {With the rapid progress in Natural Language Processing (NLP), Pre-trained Language Models (PLM) such as BERT, BioBERT, and ChatGPT have shown great potential in various medical NLP tasks. This paper surveys the cutting-edge achievements in applying PLMs to various medical NLP tasks. Specifically, we first brief PLMS and outline the research of PLMs in medicine. Next, we categorise and discuss the types of tasks in medical NLP, covering text summarisation, question-answering, machine translation, sentiment analysis, named entity recognition, information extraction, medical education, relation extraction, and text mining. For each type of task, we first provide an overview of the basic concepts, the main methodologies, the advantages of applying PLMs, the basic steps of applying PLMs application, the datasets for training and testing, and the metrics for task evaluation. Subsequently, a summary of recent important research findings is presented, analysing their motivations, strengths vs weaknesses, similarities vs differences, and discussing potential limitations. Also, we assess the quality and influence of the research reviewed in this paper by comparing the citation count of the papers reviewed and the reputation and impact of the conferences and journals where they are published. Through these indicators, we further identify the most concerned research topics currently. Finally, we look forward to future research directions, including enhancing models’ reliability, explainability, and fairness, to promote the application of PLMs in clinical practice. In addition, this survey also collect some download links of some model codes and the relevant datasets, which are valuable references for researchers applying NLP techniques in medicine and medical professionals seeking to enhance their expertise and healthcare service through AI technology.},
	urldate = {2025-07-04},
	journal = {Artificial Intelligence in Medicine},
	author = {Luo, Xudong and Deng, Zhiqi and Yang, Binxia and Luo, Michael Y.},
	month = aug,
	year = {2024},
	keywords = {BERT, GPT, Healthcare, Medical science, Natural language processing, Pre-trained language model},
	pages = {102904},
}

@article{nerella_transformers_2024,
	title = {Transformers and large language models in healthcare: {A} review},
	volume = {154},
	issn = {0933-3657},
	shorttitle = {Transformers and large language models in healthcare},
	url = {https://www.sciencedirect.com/science/article/pii/S0933365724001428},
	doi = {10.1016/j.artmed.2024.102900},
	abstract = {With Artificial Intelligence (AI) increasingly permeating various aspects of society, including healthcare, the adoption of the Transformers neural network architecture is rapidly changing many applications. Transformer is a type of deep learning architecture initially developed to solve general-purpose Natural Language Processing (NLP) tasks and has subsequently been adapted in many fields, including healthcare. In this survey paper, we provide an overview of how this architecture has been adopted to analyze various forms of healthcare data, including clinical NLP, medical imaging, structured Electronic Health Records (EHR), social media, bio-physiological signals, biomolecular sequences. Furthermore, which have also include the articles that used the transformer architecture for generating surgical instructions and predicting adverse outcomes after surgeries under the umbrella of critical care. Under diverse settings, these models have been used for clinical diagnosis, report generation, data reconstruction, and drug/protein synthesis. Finally, we also discuss the benefits and limitations of using transformers in healthcare and examine issues such as computational cost, model interpretability, fairness, alignment with human values, ethical implications, and environmental impact.},
	urldate = {2025-07-04},
	journal = {Artificial Intelligence in Medicine},
	author = {Nerella, Subhash and Bandyopadhyay, Sabyasachi and Zhang, Jiaqing and Contreras, Miguel and Siegel, Scott and Bumin, Aysegul and Silva, Brandon and Sena, Jessica and Shickel, Benjamin and Bihorac, Azra and Khezeli, Kia and Rashidi, Parisa},
	month = aug,
	year = {2024},
	keywords = {Electronic Health Records, Healthcare, Large Language Models, Medical Imaging, Natural Language Processing, Transformers},
	pages = {102900},
}

@article{khalid_privacy-preserving_2023,
	title = {Privacy-preserving artificial intelligence in healthcare: {Techniques} and applications},
	volume = {158},
	issn = {0010-4825},
	shorttitle = {Privacy-preserving artificial intelligence in healthcare},
	url = {https://www.sciencedirect.com/science/article/pii/S001048252300313X},
	doi = {10.1016/j.compbiomed.2023.106848},
	abstract = {There has been an increasing interest in translating artificial intelligence (AI) research into clinically-validated applications to improve the performance, capacity, and efficacy of healthcare services. Despite substantial research worldwide, very few AI-based applications have successfully made it to clinics. Key barriers to the widespread adoption of clinically validated AI applications include non-standardized medical records, limited availability of curated datasets, and stringent legal/ethical requirements to preserve patients’ privacy. Therefore, there is a pressing need to improvise new data-sharing methods in the age of AI that preserve patient privacy while developing AI-based healthcare applications. In the literature, significant attention has been devoted to developing privacy-preserving techniques and overcoming the issues hampering AI adoption in an actual clinical environment. To this end, this study summarizes the state-of-the-art approaches for preserving privacy in AI-based healthcare applications. Prominent privacy-preserving techniques such as Federated Learning and Hybrid Techniques are elaborated along with potential privacy attacks, security challenges, and future directions.},
	urldate = {2025-07-04},
	journal = {Computers in Biology and Medicine},
	author = {Khalid, Nazish and Qayyum, Adnan and Bilal, Muhammad and Al-Fuqaha, Ala and Qadir, Junaid},
	month = may,
	year = {2023},
	keywords = {Artificial intelligence (AI), Electronic health record (EHR), Privacy, Privacy preservation},
	pages = {106848},
}

@article{yadav_data_2023,
	title = {Data {Privacy} in {Healthcare}: {In} the {Era} of {Artificial} {Intelligence}},
	volume = {14},
	issn = {2229-5178},
	shorttitle = {Data {Privacy} in {Healthcare}},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC10718098/},
	doi = {10.4103/idoj.idoj_543_23},
	abstract = {Data Privacy has increasingly become a matter of concern in the era of large public digital respositories of data. This is particularly true in healthcare where data can be misused if traced back to patients, and brings with itself a myriad of possibilities. Bring custodians of data, as well as being at the helm of disigning studies and products that can potentially benefit products, healthcare professionals often find themselves unsure about ethical and legal constraints that undelie data sharing. In this review we touch upon the concerns, leal frameworks as well as some common practices in these respects.},
	number = {6},
	urldate = {2025-07-04},
	journal = {Indian Dermatology Online Journal},
	author = {Yadav, Neel and Pandey, Saumya and Gupta, Amit and Dudani, Pankhuri and Gupta, Somesh and Rangarajan, Krithika},
	month = oct,
	year = {2023},
	pmid = {38099022},
	pmcid = {PMC10718098},
	pages = {788--792},
}

@incollection{rodziewicz_medical_2025,
	address = {Treasure Island (FL)},
	title = {Medical {Error} {Reduction} and {Prevention}},
	copyright = {Copyright © 2025, StatPearls Publishing LLC.},
	url = {http://www.ncbi.nlm.nih.gov/books/NBK499956/},
	abstract = {Medical errors have more recently been recognized as a serious public health problem, reported as the third leading cause of death in the US. However, because medical errors are comprised of different types of failures (eg, diagnostic or medication errors) that can result in various outcomes (eg, near-miss, injury, or no harm), estimates of the incidence of medical errors vary widely in studies. One study reported that approximately 400,000 hospitalized patients experience some preventable harm each year, while another estimated that {\textgreater}200,000 patient deaths annually were due to preventable medical errors. Moreover, the reported cost of medical errors is wide-ranging, with some experts estimating \$20 billion each year and others approximating healthcare costs of \$35.7 to \$45 billion annually for hospital-acquired infections alone. The definition of a medical error varies, making analysis via uniform objectives difficult. Furthermore, a lack of standardized terminology has hindered data assessment, synthesis, and evaluation. The Institute of Medicine (IOM) Committee on Quality of Health Care in the US, which performed the first large study on medical errors, defined a medical error as "the failure of a planned action to be completed as intended or the use of a wrong plan to achieve an aim." Another definition identifies medical errors as a failure in care that may or may not result in patient harm. Regardless of the definition, medical errors are associated with high morbidity, mortality, and economic burden. Moreover, they can negatively impact the patient, their family, involved clinicians and support staff, the healthcare facility, and the community. Healthcare professionals may experience profound psychological effects (eg, anger, guilt, inadequacy, depression, and suicidal ideation) due to actual or perceived errors, which the threat of impending legal action may compound. Clinicians can also equate errors with failure, a breach of public trust, and patient injury despite their mandate to do no harm, which may lead to decreased clinical confidence. Some experts believe the term error is excessively antagonistic and perpetuates a blame culture. Due to the negative connotation, limited use of the term is prudent when documenting patient records; some experts suggest the term not be used at all. However, adverse events secondary to medical errors occur; therefore, simply discontinuing the word's usage will not prevent or reduce these errors. Uncovering the cause of these errors, as well as providing viable solutions to avoid these errors from occurring, is challenging. Healthcare professionals should be familiar with the different types of medical errors to understand better the adverse events that may be caused.  Common types of medical errors include surgical errors, diagnostic errors, medication errors, equipment failures, patient falls, hospital-acquired infections, and communication failures. By identifying the deficiencies, failures, and risk factors that lead to an adverse event, corrective measures can be developed to prevent similar errors. Encouraging individuals involved in every aspect of healthcare to report medical errors is essential to this process. Confidential reporting options are necessary to identify deficiencies or failures a system may contain. Changing workplace culture and developing protocols for addressing medical errors can encourage medical error reporting. Institutions that adopt a patient safety culture and implement corrective interventions can make healthcare safer for patients and healthcare workers. Working together, healthcare professionals can improve patient safety by identifying the contributing factors and events that result in medical errors, developing multifaceted prevention protocols, and implementing these strategies at various healthcare levels.},
	language = {eng},
	urldate = {2025-07-04},
	booktitle = {{StatPearls}},
	publisher = {StatPearls Publishing},
	author = {Rodziewicz, Thomas L. and Houseman, Benjamin and Vaqar, Sarosh and Hipskind, John E.},
	year = {2025},
	pmid = {29763131},
}

@article{van_veen_clinical_2023,
	title = {Clinical {Text} {Summarization}: {Adapting} {Large} {Language} {Models} {Can} {Outperform} {Human} {Experts}},
	issn = {2693-5015},
	shorttitle = {Clinical {Text} {Summarization}},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC10635391/},
	doi = {10.21203/rs.3.rs-3483777/v1},
	abstract = {Sifting through vast textual data and summarizing key information from electronic health records (EHR) imposes a substantial burden on how clinicians allocate their time. Although large language models (LLMs) have shown immense promise in natural language processing (NLP) tasks, their efficacy on a diverse range of clinical summarization tasks has not yet been rigorously demonstrated. In this work, we apply domain adaptation methods to eight LLMs, spanning six datasets and four distinct clinical summarization tasks: radiology reports, patient questions, progress notes, and doctor-patient dialogue. Our thorough quantitative assessment reveals trade-offs between models and adaptation methods in addition to instances where recent advances in LLMs may not improve results. Further, in a clinical reader study with ten physicians, we show that summaries from our best-adapted LLMs are preferable to human summaries in terms of completeness and correctness. Our ensuing qualitative analysis highlights challenges faced by both LLMs and human experts. Lastly, we correlate traditional quantitative NLP metrics with reader study scores to enhance our understanding of how these metrics align with physician preferences. Our research marks the first evidence of LLMs outperforming human experts in clinical text summarization across multiple tasks. This implies that integrating LLMs into clinical workflows could alleviate documentation burden, empowering clinicians to focus more on personalized patient care and the inherently human aspects of medicine.},
	urldate = {2025-07-04},
	journal = {Research Square},
	author = {Van Veen, Dave and Van Uden, Cara and Blankemeier, Louis and Delbrouck, Jean-Benoit and Aali, Asad and Bluethgen, Christian and Pareek, Anuj and Polacin, Malgorzata and Reis, Eduardo Pontes and Seehofnerová, Anna and Rohatgi, Nidhi and Hosamani, Poonam and Collins, William and Ahuja, Neera and Langlotz, Curtis P. and Hom, Jason and Gatidis, Sergios and Pauly, John and Chaudhari, Akshay S.},
	month = oct,
	year = {2023},
	pmid = {37961377},
	pmcid = {PMC10635391},
	pages = {rs.3.rs--3483777},
}

@article{ling_clinical_2015,
	title = {Clinical {Documents} {Clustering} {Based} on {Medication}/{Symptom} {Names} {Using} {Multi}-{View} {Nonnegative} {Matrix} {Factorization}},
	volume = {14},
	issn = {1558-2639},
	url = {https://ieeexplore.ieee.org/document/7111340},
	doi = {10.1109/TNB.2015.2422612},
	abstract = {Clinical documents are rich free-text data sources containing valuable medication and symptom information, which have a great potential to improve health care. In this paper, we build an integrating system for extracting medication names and symptom names from clinical notes. Then we apply nonnegative matrix factorization (NMF) and multi-view NMF to cluster clinical notes into meaningful clusters based on sample-feature matrices. Our experimental results show that multi-view NMF is a preferable method for clinical document clustering. Moreover, we find that using extracted medication/symptom names to cluster clinical documents outperforms just using words.},
	number = {5},
	urldate = {2025-07-04},
	journal = {IEEE Transactions on NanoBioscience},
	author = {Ling, Yuan and Pan, Xuelian and Li*, Guangrong and Hu, Xiaohua},
	month = jul,
	year = {2015},
	keywords = {Accuracy, Clinical document, Data mining, Design automation, Diseases, Hospitals, Informatics, Medical diagnostic imaging, clinical notes, document clustering, multi-view, nonnegative matrix factorization},
	pages = {500--504},
}

@incollection{balogh_diagnostic_2015,
	title = {The {Diagnostic} {Process}},
	url = {https://www.ncbi.nlm.nih.gov/books/NBK338593/},
	abstract = {This chapter provides an overview of diagnosis in health care, including the committee's conceptual model of the diagnostic process and a review of clinical reasoning. Diagnosis has important implications for patient care, research, and policy. Diagnosis has been described as both a process and a classification scheme, or a “pre-existing set of categories agreed upon by the medical profession to designate a specific condition” (Jutel, 2009).1 When a diagnosis is accurate and made in a timely manner, a patient has the best opportunity for a positive health outcome because clinical decision making will be tailored to a correct understanding of the patient's health problem (Holmboe and Durning, 2014). In addition, public policy decisions are often influenced by diagnostic information, such as setting payment policies, resource allocation decisions, and research priorities (Jutel, 2009; Rosenberg, 2002; WHO, 2012).},
	language = {en},
	urldate = {2025-07-04},
	booktitle = {Improving {Diagnosis} in {Health} {Care}},
	publisher = {National Academies Press (US)},
	author = {Balogh, Erin P. and Miller, Bryan T. and Ball, John R. and Care, Committee on Diagnostic Error in Health and Services, Board on Health Care and Medicine, Institute of and The National Academies of Sciences, Engineering},
	month = dec,
	year = {2015},
}

@article{luo_pre-trained_2024-1,
	title = {Pre-trained language models in medicine: {A} survey},
	volume = {154},
	issn = {0933-3657},
	shorttitle = {Pre-trained language models in medicine},
	url = {https://www.sciencedirect.com/science/article/pii/S0933365724001465},
	doi = {10.1016/j.artmed.2024.102904},
	abstract = {With the rapid progress in Natural Language Processing (NLP), Pre-trained Language Models (PLM) such as BERT, BioBERT, and ChatGPT have shown great potential in various medical NLP tasks. This paper surveys the cutting-edge achievements in applying PLMs to various medical NLP tasks. Specifically, we first brief PLMS and outline the research of PLMs in medicine. Next, we categorise and discuss the types of tasks in medical NLP, covering text summarisation, question-answering, machine translation, sentiment analysis, named entity recognition, information extraction, medical education, relation extraction, and text mining. For each type of task, we first provide an overview of the basic concepts, the main methodologies, the advantages of applying PLMs, the basic steps of applying PLMs application, the datasets for training and testing, and the metrics for task evaluation. Subsequently, a summary of recent important research findings is presented, analysing their motivations, strengths vs weaknesses, similarities vs differences, and discussing potential limitations. Also, we assess the quality and influence of the research reviewed in this paper by comparing the citation count of the papers reviewed and the reputation and impact of the conferences and journals where they are published. Through these indicators, we further identify the most concerned research topics currently. Finally, we look forward to future research directions, including enhancing models’ reliability, explainability, and fairness, to promote the application of PLMs in clinical practice. In addition, this survey also collect some download links of some model codes and the relevant datasets, which are valuable references for researchers applying NLP techniques in medicine and medical professionals seeking to enhance their expertise and healthcare service through AI technology.},
	urldate = {2025-07-04},
	journal = {Artificial Intelligence in Medicine},
	author = {Luo, Xudong and Deng, Zhiqi and Yang, Binxia and Luo, Michael Y.},
	month = aug,
	year = {2024},
	keywords = {BERT, GPT, Healthcare, Medical science, Natural language processing, Pre-trained language model},
	pages = {102904},
}

@article{almohaimeed_abstractive_2025,
	title = {Abstractive text summarization: {A} comprehensive survey of techniques, systems, and challenges},
	volume = {57},
	issn = {1574-0137},
	shorttitle = {Abstractive text summarization},
	url = {https://www.sciencedirect.com/science/article/pii/S1574013725000383},
	doi = {10.1016/j.cosrev.2025.100762},
	abstract = {ive text summarization addresses information overload by generating paraphrased content that mimics human expression, yet it faces significant computational and linguistic challenges. This paper presents a detailed functional taxonomy of abstractive summarization, structured along four dimensions: techniques (including structure-based, semantic, and deep learning approaches, including large language models), system architectures (ranging from single-model to multi-agent and human-in-the-loop interactive systems), evaluation methods (covering lexical, semantic, and human-centered assessments), and datasets. Our taxonomy explicitly distinguishes techniques from architectures to clarify how methodological strategies are operationalized in practice. We examine pressing multilingual challenges such as linguistic complexity, data scarcity, and performance disparities in cross-lingual transfer, particularly for low-resource languages. Additionally, we address persistent issues such as factual inaccuracies, content hallucinations, and biases in widely used evaluation metrics. The paper highlights emerging trends—including cross-lingual summarization, interactive summarization systems, and ethically grounded frameworks—as key directions for future research. This synthesis not only maps the current landscape but also outlines pathways to enhance the accuracy, reliability, and applicability of abstractive summarization in real-world settings.},
	urldate = {2025-07-04},
	journal = {Computer Science Review},
	author = {Almohaimeed, Norah and Azmi, Aqil M.},
	month = aug,
	year = {2025},
	keywords = {Abstractive summarization, Datasets, Evaluation methods, Summarization techniques, System architectures, Taxonomy},
	pages = {100762},
}

@article{shakil_abstractive_2024,
	title = {Abstractive {Text} {Summarization}: {State} of the {Art}, {Challenges}, and {Improvements}},
	volume = {603},
	issn = {09252312},
	shorttitle = {Abstractive {Text} {Summarization}},
	url = {http://arxiv.org/abs/2409.02413},
	doi = {10.1016/j.neucom.2024.128255},
	abstract = {Specifically focusing on the landscape of abstractive text summarization, as opposed to extractive techniques, this survey presents a comprehensive overview, delving into state-of-the-art techniques, prevailing challenges, and prospective research directions. We categorize the techniques into traditional sequence-to-sequence models, pre-trained large language models, reinforcement learning, hierarchical methods, and multi-modal summarization. Unlike prior works that did not examine complexities, scalability and comparisons of techniques in detail, this review takes a comprehensive approach encompassing state-of-the-art methods, challenges, solutions, comparisons, limitations and charts out future improvements - providing researchers an extensive overview to advance abstractive summarization research. We provide vital comparison tables across techniques categorized - offering insights into model complexity, scalability and appropriate applications. The paper highlights challenges such as inadequate meaning representation, factual consistency, controllable text summarization, cross-lingual summarization, and evaluation metrics, among others. Solutions leveraging knowledge incorporation and other innovative strategies are proposed to address these challenges. The paper concludes by highlighting emerging research areas like factual inconsistency, domain-specific, cross-lingual, multilingual, and long-document summarization, as well as handling noisy data. Our objective is to provide researchers and practitioners with a structured overview of the domain, enabling them to better understand the current landscape and identify potential areas for further research and improvement.},
	urldate = {2025-07-04},
	journal = {Neurocomputing},
	author = {Shakil, Hassan and Farooq, Ahmad and Kalita, Jugal},
	month = oct,
	year = {2024},
	note = {arXiv:2409.02413 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computation and Language, Computer Science - Machine Learning},
	pages = {128255},
}

@article{ando_exploring_2022,
	title = {Exploring optimal granularity for extractive summarization of unstructured health records: {Analysis} of the largest multi-institutional archive of health records in {Japan}},
	volume = {1},
	issn = {2767-3170},
	shorttitle = {Exploring optimal granularity for extractive summarization of unstructured health records},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC9931252/},
	doi = {10.1371/journal.pdig.0000099},
	abstract = {Automated summarization of clinical texts can reduce the burden of medical professionals. “Discharge summaries” are one promising application of the summarization, because they can be generated from daily inpatient records. Our preliminary experiment suggests that 20–31\% of the descriptions in discharge summaries overlap with the content of the inpatient records. However, it remains unclear how the summaries should be generated from the unstructured source. To decompose the physician’s summarization process, this study aimed to identify the optimal granularity in summarization. We first defined three types of summarization units with different granularities to compare the performance of the discharge summary generation: whole sentences, clinical segments, and clauses. We defined clinical segments in this study, aiming to express the smallest medically meaningful concepts. To obtain the clinical segments, it was necessary to automatically split the texts in the first stage of the pipeline. Accordingly, we compared rule-based methods and a machine learning method, and the latter outperformed the formers with an F1 score of 0.846 in the splitting task. Next, we experimentally measured the accuracy of extractive summarization using the three types of units, based on the ROUGE-1 metric, on a multi-institutional national archive of health records in Japan. The measured accuracies of extractive summarization using whole sentences, clinical segments, and clauses were 31.91, 36.15, and 25.18, respectively. We found that the clinical segments yielded higher accuracy than sentences and clauses. This result indicates that summarization of inpatient records demands finer granularity than sentence-oriented processing. Although we used only Japanese health records, it can be interpreted as follows: physicians extract “concepts of medical significance” from patient records and recombine them in new contexts when summarizing chronological clinical records, rather than simply copying and pasting topic sentences. This observation suggests that a discharge summary is created by higher-order information processing over concepts on sub-sentence level, which may guide future research in this field., Medical practice includes significant paperwork, and therefore, automated processing of clinical texts can reduce medical professionals’ burden. Accordingly, we focused on hospitals’ discharge summaries from daily inpatient records stored in Electric Health Records. By applying summarization technologies, which are well-studied in Natural Language Processing, discharge summaries could be generated automatically from the source texts. However, automated summarization of daily inpatient records involves various technical topics and challenges, and the generation of discharge summaries is a complex process of mixing extractive and abstractive summarization. Thus, in this study, we explored optimal granularity for extractive summarization, attempting to decompose actual physicians’ processing. In the experiments, we used three types of summarization units with different granularities to compare performances of discharge summary generation: whole sentences, clinical segments, and clauses. We originally defined clinical segments, aiming to express the smallest medically meaningful concepts. The result indicated that sub-sentence processing, larger than clauses, improves the quality of the summaries. This finding can guide future development of medical documents’ automated summarization.},
	number = {9},
	urldate = {2025-07-04},
	journal = {PLOS Digital Health},
	author = {Ando, Kenichiro and Okumura, Takashi and Komachi, Mamoru and Horiguchi, Hiromasa and Matsumoto, Yuji},
	month = sep,
	year = {2022},
	pmid = {36812582},
	pmcid = {PMC9931252},
	pages = {e0000099},
}

@misc{noauthor_extractive_nodate,
	title = {Extractive {Summarization} - an overview {\textbar} {ScienceDirect} {Topics}},
	url = {https://www.sciencedirect.com/topics/computer-science/extractive-summarization},
	urldate = {2025-07-04},
}

@article{maleki_varnosfaderani_role_2024,
	title = {The {Role} of {AI} in {Hospitals} and {Clinics}: {Transforming} {Healthcare} in the 21st {Century}},
	volume = {11},
	issn = {2306-5354},
	shorttitle = {The {Role} of {AI} in {Hospitals} and {Clinics}},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC11047988/},
	doi = {10.3390/bioengineering11040337},
	abstract = {As healthcare systems around the world face challenges such as escalating costs, limited access, and growing demand for personalized care, artificial intelligence (AI) is emerging as a key force for transformation. This review is motivated by the urgent need to harness AI’s potential to mitigate these issues and aims to critically assess AI’s integration in different healthcare domains. We explore how AI empowers clinical decision-making, optimizes hospital operation and management, refines medical image analysis, and revolutionizes patient care and monitoring through AI-powered wearables. Through several case studies, we review how AI has transformed specific healthcare domains and discuss the remaining challenges and possible solutions. Additionally, we will discuss methodologies for assessing AI healthcare solutions, ethical challenges of AI deployment, and the importance of data privacy and bias mitigation for responsible technology use. By presenting a critical assessment of AI’s transformative potential, this review equips researchers with a deeper understanding of AI’s current and future impact on healthcare. It encourages an interdisciplinary dialogue between researchers, clinicians, and technologists to navigate the complexities of AI implementation, fostering the development of AI-driven solutions that prioritize ethical standards, equity, and a patient-centered approach.},
	number = {4},
	urldate = {2025-07-03},
	journal = {Bioengineering},
	author = {Maleki Varnosfaderani, Shiva and Forouzanfar, Mohamad},
	month = mar,
	year = {2024},
	pmid = {38671759},
	pmcid = {PMC11047988},
	pages = {337},
}

@article{supriyono_survey_2024,
	title = {A survey of text summarization: {Techniques}, evaluation and challenges},
	volume = {7},
	issn = {2949-7191},
	shorttitle = {A survey of text summarization},
	url = {https://www.sciencedirect.com/science/article/pii/S2949719124000189},
	doi = {10.1016/j.nlp.2024.100070},
	abstract = {This paper explores the complex field of text summarization in Natural Language Processing (NLP), with particular attention to the development and importance of semantic understanding. Text summarization is a crucial component of natural language processing (NLP), which helps to translate large amounts of textual data into clear and understandable representations. As the story progresses, it demonstrates the dynamic transition from simple syntactic structures to sophisticated models with semantic comprehension. In order to effectively summarize, syntactic, semantic, and pragmatic concerns become crucial, highlighting the necessity of capturing not only grammar but also the context and underlying meaning. It examines the wide range of summarization models, from conventional extractive techniques to state-of-the-art tools like pre-trained models. Applications are found in many different fields, demonstrating how versatile summarizing techniques are. Semantic drift and domain-specific knowledge remain obstacles, despite progress. In the future, the study predicts developments like artificial intelligence integration and transfer learning, which motivates academics to investigate these prospects for advancement. The approach, which is based on the PRISMA framework, emphasizes a methodical and open literature review. The work attempts to further natural language processing (NLP) and text summarization by combining various research findings and suggesting future research directions in this dynamic subject.},
	urldate = {2025-07-03},
	journal = {Natural Language Processing Journal},
	author = {{Supriyono} and Wibawa, Aji Prasetya and {Suyono} and Kurniawan, Fachrul},
	month = jun,
	year = {2024},
	keywords = {Natural language processing, PRISMA, Semantic, Syntactic, Text summarization, Transfer learning},
	pages = {100070},
}

@article{jiang_pre-pandemic_2023,
	title = {Pre-pandemic assessment: a decade of progress in electronic health record adoption among {U}.{S}. hospitals},
	volume = {1},
	issn = {2976-5390},
	shorttitle = {Pre-pandemic assessment},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC10986221/},
	doi = {10.1093/haschl/qxad056},
	abstract = {As the COVID-19 pandemic loomed, the adoption of electronic health records (EHRs) in US hospitals became a pivotal concern. This study provides a pre-pandemic assessment, highlighting a decade of progress in EHR adoption from 2009 to 2019, with the last available survey conducted from January to June of 2020. It delves into the current EHR adoption rates, variations across different hospital categories, the influence of major vendors, and the challenges in implementing these systems. The study found that basic EHR adoption surged from 6.6\% to 81.2\%, while comprehensive systems increased from 3.6\% to 63.2\%. Despite this growth, the findings point to enduring disparities among hospitals, a concentrated market share by 6 vendors (90\%), and significant concerns regarding maintenance costs. These insights provide an invaluable snapshot of the state of EHR adoption at the brink of the pandemic, serving as a benchmark to assess hospitals’ readiness to utilize digital infrastructure in health care. The conclusions underscore the necessity for strategic policy interventions to encourage a competitive landscape and guarantee equitable access, ultimately strengthening the health care system's responsiveness to global health crises such as COVID-19.},
	number = {5},
	urldate = {2025-07-03},
	journal = {Health Affairs Scholar},
	author = {Jiang, John (Xuefeng) and Qi, Kangkang and Bai, Ge and Schulman, Kevin},
	month = oct,
	year = {2023},
	pmid = {38756982},
	pmcid = {PMC10986221},
	pages = {qxad056},
}

@article{de_groot_nursing_2022,
	title = {Nursing documentation and its relationship with perceived nursing workload: a mixed-methods study among community nurses},
	volume = {21},
	issn = {1472-6955},
	shorttitle = {Nursing documentation and its relationship with perceived nursing workload},
	url = {https://doi.org/10.1186/s12912-022-00811-7},
	doi = {10.1186/s12912-022-00811-7},
	abstract = {The time that nurses spent on documentation can be substantial and burdensome. To date it was unknown if documentation activities are related to the workload that nurses perceive. A distinction between clinical documentation and organizational documentation seems relevant. This study aims to gain insight into community nurses’ views on a potential relationship between their clinical and organizational documentation activities and their perceived nursing workload.},
	number = {1},
	urldate = {2025-07-03},
	journal = {BMC Nursing},
	author = {De Groot, Kim and De Veer, Anke J. E. and Munster, Anne M. and Francke, Anneke L. and Paans, Wolter},
	month = jan,
	year = {2022},
	keywords = {Documentation burden, Electronic health record, Home care, Mixed-methods research, Nursing documentation, Nursing process, Nursing workload, User-friendliness},
	pages = {34},
}

@misc{noauthor_allocation_nodate,
	title = {Allocation of {Physician} {Time} in {Ambulatory} {Practice}: {A} {Time} and {Motion} {Study} in 4 {Specialties} {\textbar} {Annals} of {Internal} {Medicine}},
	url = {https://www.acpjournals.org/doi/10.7326/M16-0961},
	urldate = {2025-07-03},
}
